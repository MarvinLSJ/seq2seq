{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from utils import load_embed, save_embed, get_embedding\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Vocab\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'experiment_name': 'seq2seq_baseline',\n",
    "    'task': 'train',\n",
    "    'make_dict': False,\n",
    "    'data_preprocessing': False,\n",
    "    'src_lang': 'chinese',\n",
    "    'tgt_lang': 'english',\n",
    "    'max_length': 60,\n",
    "\n",
    "    'ckpt_dir': 'ckpt/',\n",
    "\n",
    "    'training':{\n",
    "        'num_epochs': 20,\n",
    "        'learning_rate': 0.01,\n",
    "        'optimizer': 'sgd'\n",
    "    },\n",
    "    \n",
    "    'embedding':{\n",
    "        'cn_embed_path': 'data/sgns.merge.bigram.bz2',\n",
    "        'en_embed_path': 'data/wiki.en.vec',\n",
    "        'cur_cn_embedding_path': 'data/cn_embed.pkl',\n",
    "        'cur_en_embedding_path': 'data/en_embed.pkl'\n",
    "    },\n",
    "        \n",
    "    'model':{\n",
    "        'fc_dim': 100,\n",
    "        'name': 'seq2seq',\n",
    "        'embed_size': 300,\n",
    "        'batch_size': 64,\n",
    "        'embedding_freeze': False,\n",
    "        'encoder':{\n",
    "            'hidden_size': 150,\n",
    "            'num_layers': 1,\n",
    "            'bidirectional': False,\n",
    "            'dropout': 0.5,\n",
    "        },  \n",
    "        'decoder':{\n",
    "            'hidden_size': 150,\n",
    "            'num_layers': 1,\n",
    "            'bidirectional': False,\n",
    "            'dropout': 0.5,\n",
    "        },\n",
    "        'xgboost':{\n",
    "            # \n",
    "        }\n",
    "    },   \n",
    "    \n",
    "    'result':{\n",
    "        'filename':'result.txt',\n",
    "        'filepath':'res/',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = pd.read_csv('data/cn_split.csv')\n",
    "en = pd.read_csv('data/en.csv')\n",
    "pair = pd.concat([cn, en], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "msk = np.random.rand(len(pair)) < 0.8\n",
    "train = pair[msk]\n",
    "valid = pair[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "\n",
    "class myDS(Dataset):\n",
    "\n",
    "    def __init__(self, df, src_lang, tgt_lang, src_sents, tgt_sents):\n",
    "        # Assign vocabularies.\n",
    "        self.src = df[src_lang].tolist()\n",
    "        self.tgt = df[tgt_lang].tolist()\n",
    "        self.src_vocab = Vocab(src_sents, sos_token='<sos>', eos_token='<eos>', unk_token='<unk>')\n",
    "        self.tgt_vocab = Vocab(tgt_sents, sos_token='<sos>', eos_token='<eos>', unk_token='<unk>')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Split sentence into words.\n",
    "        src_words = self.src[idx].split()\n",
    "        tgt_words = self.tgt[idx].split()\n",
    "\n",
    "        # Add <SOS> and <EOS> tokens.\n",
    "        src_words = [self.src_vocab.sos_token] + src_words + [self.src_vocab.eos_token]\n",
    "        tgt_words = [self.tgt_vocab.sos_token] + tgt_words + [self.tgt_vocab.eos_token]\n",
    "\n",
    "        # Lookup word ids in vocabularies.\n",
    "        src_ids = [self.src_vocab.word2id(word) for word in src_words]\n",
    "        tgt_ids = [self.tgt_vocab.word2id(word) for word in tgt_words]\n",
    "\n",
    "#         print(src_words)\n",
    "#         print(tgt_words)\n",
    "        \n",
    "        return src_ids, tgt_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_lang = 'chinese'\n",
    "# tgt_lang = 'english'\n",
    "\n",
    "src_lang = config['src_lang']\n",
    "tgt_lang = config['tgt_lang']\n",
    "\n",
    "# All senteneces (including train and valid)\n",
    "src_sents = pair[src_lang].tolist()\n",
    "tgt_sents = pair[tgt_lang].tolist() \n",
    "\n",
    "train_ds = myDS(train, src_lang, tgt_lang, src_sents, tgt_sents)\n",
    "valid_ds = myDS(valid, src_lang, tgt_lang, src_sents, tgt_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing chinese - english NMT Model.\n",
      "\n",
      "Preparing 80044 Training sentence pairs; 19956 Validation pairs.\n",
      "\n",
      "With 53717 source language words; 35029 target language words.\n"
     ]
    }
   ],
   "source": [
    "print('Preparing {} - {} NMT Model.\\n'.format(src_lang, tgt_lang))\n",
    "print('Preparing {} Training sentence pairs; {} Validation pairs.\\n\\nWith {} source language words; {} target language words.'.format(\n",
    "    train_ds.__len__(), valid_ds.__len__(), len(train_ds.src_vocab._id2word), len(train_ds.tgt_vocab._id2word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_ds, shuffle=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_embed = config['src_embedding_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0984,  0.3723, -0.5471,  0.6153,  0.1835,  0.1941, -0.1816,\n",
      "          -0.0765,  0.4914,  0.0046,  0.3725, -0.1949,  0.0384,  0.1225,\n",
      "          -0.0020,  0.3702,  0.0790, -0.5191,  0.3687,  0.3941,  0.2960,\n",
      "          -0.0864,  0.0015, -0.4496, -0.0343,  0.0303,  0.1771,  0.1550,\n",
      "           0.0901,  0.2889, -0.0573,  0.0665,  0.0841, -0.2436, -0.2808,\n",
      "          -0.3468,  0.3524, -0.2269, -0.1008,  0.1054, -0.0217, -0.3162,\n",
      "          -0.1317, -0.2450,  0.1043,  0.3874,  0.0106,  0.0504, -0.3197,\n",
      "          -0.2544,  0.5210,  0.1725, -0.1383, -0.0931, -0.0950,  0.1365,\n",
      "           0.3695, -0.1193,  0.0436, -0.4731, -0.4016,  0.1256, -0.1041,\n",
      "           0.0385, -0.1871, -0.0948,  0.0303,  0.1189, -0.2352,  0.1065,\n",
      "           0.0145, -0.1852,  0.0066, -0.3150, -0.1500,  0.1299,  0.3527,\n",
      "           0.0238,  0.4453,  0.3363,  0.5722, -0.1144, -0.2895, -0.0655,\n",
      "          -0.0344, -0.0216, -0.1409, -0.3890,  0.2270,  0.1759,  0.2728,\n",
      "          -0.3442,  0.2637,  0.0383,  0.1057,  0.2736,  0.0785,  0.2007,\n",
      "          -0.3014,  0.0172,  0.0446,  0.1151,  0.2460,  0.0465, -0.4560,\n",
      "           0.4849,  0.2684, -0.2148,  0.0359,  0.2300,  0.0670, -0.2825,\n",
      "          -0.1082,  0.2572,  0.1516, -0.0683,  0.0705,  0.5024,  0.1414,\n",
      "           0.0630,  0.1151, -0.0196,  0.0986,  0.0466, -0.3475, -0.0331,\n",
      "          -0.3618, -0.4808,  0.1897, -0.0949, -0.4302,  0.1409, -0.1629,\n",
      "          -0.1495,  0.2100,  0.0088,  0.1366, -0.4814,  0.1001, -0.1407,\n",
      "           0.3052, -0.4969,  0.1965,  0.1549,  0.1252, -0.3875, -0.0177,\n",
      "           0.1195,  0.4690, -0.1409]]], grad_fn=<CatBackward>)\n",
      "tensor([[[-0.2651,  0.1113, -0.1978,  0.3772,  0.1029,  0.3946, -0.1115,\n",
      "          -0.0762,  0.3474,  0.0782,  0.2191, -0.1720,  0.1106,  0.0205,\n",
      "           0.0595,  0.0936,  0.0196, -0.0900,  0.1006,  0.2221,  0.2046,\n",
      "          -0.0818, -0.0138, -0.1720,  0.0064,  0.0983,  0.0105,  0.2456,\n",
      "           0.3173,  0.0597,  0.0963,  0.0136,  0.0657, -0.0735, -0.0805,\n",
      "          -0.2429,  0.1472, -0.0247, -0.0765,  0.1884,  0.1163, -0.1044,\n",
      "          -0.1197, -0.0655,  0.0537,  0.2324,  0.0133,  0.0011,  0.0155,\n",
      "          -0.0391,  0.2547,  0.2927, -0.0637, -0.0966, -0.1622,  0.1102,\n",
      "           0.2935,  0.0116, -0.0510, -0.1368, -0.1449,  0.0795,  0.0301,\n",
      "          -0.0909, -0.1211, -0.1285,  0.0055,  0.1134, -0.2242,  0.0081,\n",
      "          -0.0991,  0.0255, -0.1503, -0.1730, -0.1845, -0.0541,  0.1649,\n",
      "          -0.0423,  0.1743,  0.0947,  0.3706, -0.1129, -0.3369,  0.0230,\n",
      "          -0.0987, -0.0293, -0.1184, -0.2881,  0.0555,  0.1779,  0.1967,\n",
      "          -0.0994,  0.2198,  0.1173, -0.0124, -0.0064,  0.0965,  0.1717,\n",
      "          -0.1560,  0.1461, -0.0406,  0.1072,  0.2424, -0.0173, -0.3425,\n",
      "           0.1637,  0.2165, -0.0102,  0.0557,  0.1248,  0.0786, -0.2465,\n",
      "           0.0305, -0.0386,  0.0088,  0.0009, -0.0105,  0.1349,  0.1288,\n",
      "           0.0676,  0.0352, -0.1346,  0.2231,  0.0849, -0.2542, -0.1382,\n",
      "          -0.2935, -0.1576,  0.2094,  0.0115, -0.1604,  0.1493, -0.0961,\n",
      "          -0.1282,  0.2042, -0.0437,  0.1470, -0.2339,  0.1059,  0.0458,\n",
      "           0.3163, -0.1527,  0.0468,  0.1743, -0.0174, -0.2528, -0.1767,\n",
      "           0.1434,  0.1051, -0.0153]]], grad_fn=<CatBackward>)\n",
      "tensor([[[-0.1894, -0.0408, -0.0700,  0.1689, -0.0065,  0.3264, -0.0638,\n",
      "           0.1426,  0.1759, -0.0057,  0.1850,  0.0251,  0.0325,  0.0350,\n",
      "           0.0593,  0.0532, -0.0082, -0.0775,  0.1048,  0.1798, -0.0352,\n",
      "           0.0298, -0.1265,  0.0385, -0.0610,  0.1406,  0.0280,  0.2555,\n",
      "           0.1873, -0.0182,  0.0755,  0.0705, -0.0095,  0.0860, -0.0784,\n",
      "          -0.0927,  0.2746,  0.0874,  0.1227, -0.0168, -0.0190,  0.1114,\n",
      "          -0.0968,  0.0355,  0.0617,  0.1426,  0.0393, -0.0970,  0.0443,\n",
      "          -0.0590,  0.1668,  0.3661, -0.0847, -0.1177, -0.1137,  0.0537,\n",
      "           0.1776, -0.0556, -0.1360, -0.0735, -0.0231,  0.0260,  0.0489,\n",
      "          -0.0508, -0.1632, -0.0394, -0.0076,  0.2130, -0.1177, -0.0284,\n",
      "          -0.1835,  0.0644, -0.0689, -0.2195, -0.1221, -0.0742,  0.0667,\n",
      "          -0.0404,  0.1272, -0.0884,  0.2781, -0.0849, -0.2488, -0.0220,\n",
      "          -0.0453, -0.0903, -0.0037, -0.2898, -0.0410,  0.0923,  0.1391,\n",
      "          -0.0167,  0.0788,  0.1247, -0.0861,  0.1734,  0.1907,  0.0963,\n",
      "           0.0909,  0.1634, -0.0213,  0.1396, -0.1168,  0.0479, -0.1615,\n",
      "           0.0918,  0.0954,  0.0402,  0.1523,  0.0521, -0.0133, -0.1756,\n",
      "           0.0386,  0.1870,  0.0357, -0.0672, -0.0620,  0.1271,  0.0860,\n",
      "           0.0424,  0.1850, -0.1907,  0.1787, -0.1003, -0.0119, -0.1274,\n",
      "          -0.1865, -0.0503,  0.0929, -0.0706,  0.0350,  0.1603,  0.0371,\n",
      "          -0.1607,  0.0653, -0.0482,  0.0038, -0.0960,  0.0582,  0.1790,\n",
      "           0.2045, -0.0200, -0.0325,  0.2378, -0.1811, -0.1847, -0.1446,\n",
      "          -0.0265,  0.0361,  0.0653]]], grad_fn=<CatBackward>)\n",
      "tensor([[[-0.0339, -0.1523, -0.1826,  0.0657, -0.0636,  0.2753, -0.1164,\n",
      "          -0.0105,  0.1059,  0.1513,  0.0186, -0.0321, -0.0139,  0.0324,\n",
      "           0.0308,  0.0965,  0.0006, -0.0215,  0.0391,  0.1220, -0.0560,\n",
      "           0.0517, -0.1149,  0.1020, -0.0192,  0.1371,  0.1237,  0.0815,\n",
      "           0.1990, -0.0569,  0.0974,  0.1008,  0.0976,  0.0066, -0.0524,\n",
      "           0.0359,  0.1541,  0.0492,  0.0255, -0.1073,  0.0406,  0.0190,\n",
      "          -0.0887, -0.0437,  0.0186,  0.0376,  0.0159,  0.0561,  0.1524,\n",
      "          -0.0454,  0.1591,  0.1454, -0.0760, -0.0310, -0.0365,  0.0282,\n",
      "           0.1809, -0.1662, -0.1123, -0.1109, -0.0415,  0.0440,  0.0492,\n",
      "           0.0909, -0.0027, -0.0065, -0.0045,  0.0645, -0.1499, -0.0054,\n",
      "          -0.1116, -0.0032, -0.1292, -0.0825,  0.0023,  0.0274, -0.1067,\n",
      "           0.0800, -0.0164, -0.1334,  0.1882,  0.0082, -0.1645, -0.0069,\n",
      "          -0.0445, -0.0667,  0.0593, -0.0705, -0.0685,  0.0380,  0.1031,\n",
      "          -0.0694,  0.1105,  0.1409, -0.0035,  0.1078,  0.1307,  0.0998,\n",
      "           0.0285,  0.0366,  0.0279,  0.2361,  0.0276, -0.0807, -0.0843,\n",
      "           0.0456, -0.0289,  0.1580,  0.0570,  0.0528,  0.1029, -0.0121,\n",
      "           0.0410,  0.1138,  0.0334, -0.0606, -0.0670,  0.0028,  0.0495,\n",
      "          -0.0762, -0.0810, -0.1077, -0.0074, -0.1115, -0.0887, -0.0733,\n",
      "          -0.1327, -0.0206,  0.0342, -0.1106,  0.1123,  0.1363,  0.0172,\n",
      "          -0.0880,  0.0585, -0.0576,  0.0291, -0.0158,  0.1377,  0.2075,\n",
      "           0.2318,  0.1898, -0.0368,  0.0913, -0.1563,  0.0015, -0.0488,\n",
      "           0.0845,  0.0748, -0.0242]]], grad_fn=<CatBackward>)\n",
      "tensor([[[-0.0089, -0.1619, -0.1036,  0.0658, -0.1396,  0.2561, -0.0408,\n",
      "          -0.0138,  0.0523,  0.0976,  0.1342, -0.0745,  0.0424,  0.0972,\n",
      "           0.0445,  0.1128,  0.1496,  0.0228,  0.0444,  0.0592, -0.1704,\n",
      "           0.0387, -0.1056,  0.1002,  0.0518,  0.0745,  0.0798,  0.0771,\n",
      "           0.1885, -0.0848,  0.1592,  0.1734,  0.1006, -0.1302, -0.0349,\n",
      "           0.0975,  0.1440,  0.0666, -0.0551, -0.0559, -0.0567, -0.1015,\n",
      "          -0.1539, -0.0681,  0.0802,  0.0337, -0.0216,  0.0383,  0.1579,\n",
      "           0.0183,  0.0398,  0.1059, -0.0033, -0.0341, -0.0361,  0.0987,\n",
      "           0.2037, -0.0806, -0.0467, -0.0815,  0.0115, -0.0329,  0.1132,\n",
      "           0.1620,  0.0689, -0.1146, -0.0479, -0.0751, -0.0911, -0.0503,\n",
      "          -0.0536, -0.0745, -0.2997,  0.0088, -0.0562,  0.0426, -0.0601,\n",
      "           0.0821, -0.0732, -0.0446,  0.1123, -0.0846, -0.1353,  0.0438,\n",
      "           0.0165, -0.0920,  0.0307,  0.1078, -0.0001,  0.0513,  0.0943,\n",
      "          -0.0324,  0.0944,  0.1158,  0.0675,  0.1234,  0.0359,  0.0853,\n",
      "          -0.0496,  0.0881, -0.1220,  0.2019,  0.0497, -0.0909, -0.0363,\n",
      "           0.0440, -0.0620,  0.1696,  0.0785,  0.0629,  0.0745, -0.1364,\n",
      "          -0.0046,  0.1081, -0.0785, -0.0133, -0.0209, -0.0285, -0.0010,\n",
      "          -0.0752, -0.0791, -0.1255,  0.0963, -0.0405, -0.1377,  0.0786,\n",
      "          -0.1273, -0.0173, -0.0341, -0.1468,  0.1035,  0.0651,  0.0739,\n",
      "           0.0022,  0.1464,  0.0028,  0.1345,  0.0204, -0.0448,  0.1534,\n",
      "           0.1574,  0.1561, -0.1158,  0.0362, -0.1501,  0.0531, -0.0493,\n",
      "           0.0061,  0.1218, -0.0295]]], grad_fn=<CatBackward>)\n",
      "tensor([[[-0.1026, -0.1960, -0.1146,  0.0041, -0.2570,  0.2717,  0.0781,\n",
      "          -0.0220, -0.0163,  0.0493,  0.1969, -0.0333, -0.0899, -0.0466,\n",
      "           0.0840, -0.0661,  0.0354, -0.0727,  0.0139,  0.0083, -0.2101,\n",
      "           0.1079, -0.1087,  0.1002,  0.0133,  0.1245,  0.1665,  0.0687,\n",
      "           0.1515, -0.1056,  0.0592,  0.0432,  0.0553, -0.1146,  0.0433,\n",
      "          -0.0046,  0.1337,  0.1757, -0.0919, -0.0980, -0.0047,  0.0384,\n",
      "          -0.1309, -0.1273, -0.0583,  0.2058,  0.0966,  0.0071,  0.0589,\n",
      "           0.0431, -0.0064,  0.0622, -0.0594, -0.0969, -0.0474,  0.0427,\n",
      "           0.2963, -0.1201,  0.0193,  0.0224,  0.0202, -0.0759,  0.0988,\n",
      "           0.0706, -0.0836, -0.1476, -0.1133, -0.1076, -0.0230,  0.0138,\n",
      "          -0.1017, -0.0298, -0.2268, -0.0682, -0.0844, -0.0995,  0.0245,\n",
      "          -0.0399, -0.0833, -0.0386,  0.1613, -0.1654, -0.1566,  0.1125,\n",
      "           0.1388, -0.0860,  0.0255,  0.0601, -0.1168, -0.0010,  0.0877,\n",
      "          -0.1113, -0.0830,  0.0276,  0.0779,  0.1664,  0.0781,  0.1453,\n",
      "          -0.0027,  0.0899, -0.2279,  0.2270, -0.0504, -0.0141, -0.0656,\n",
      "          -0.0179, -0.0909,  0.1930,  0.0807,  0.0309,  0.0498, -0.1006,\n",
      "          -0.0998,  0.1317, -0.1833, -0.0813, -0.0066, -0.0743,  0.0480,\n",
      "          -0.0090, -0.0556, -0.1524, -0.0210,  0.0109,  0.0448,  0.0388,\n",
      "          -0.0515, -0.0015, -0.0175, -0.0276,  0.0702,  0.0333,  0.0184,\n",
      "          -0.1297,  0.0772,  0.0433,  0.0908,  0.0399, -0.0173,  0.1171,\n",
      "           0.2299,  0.2790, -0.1769,  0.0867, -0.2355,  0.0215,  0.1181,\n",
      "           0.0442,  0.0788,  0.1311]]], grad_fn=<CatBackward>)\n",
      "tensor([[[-0.1029, -0.1858, -0.1688,  0.1234, -0.0997,  0.1653, -0.0067,\n",
      "           0.0511, -0.0555,  0.1159,  0.2491, -0.0189,  0.0464,  0.0082,\n",
      "           0.0103, -0.0947, -0.0267,  0.0172,  0.0541,  0.0317, -0.1290,\n",
      "           0.0565, -0.1838,  0.0926,  0.0190,  0.1340,  0.0758,  0.1376,\n",
      "           0.2375, -0.1609, -0.0316,  0.0213,  0.1897, -0.0723,  0.0988,\n",
      "           0.0643,  0.1906,  0.0084, -0.1249, -0.0864, -0.1207,  0.1980,\n",
      "          -0.1556, -0.0754,  0.0217,  0.0959,  0.0076,  0.0220,  0.0451,\n",
      "           0.0009, -0.0508,  0.0494, -0.0437, -0.0450,  0.0177, -0.0938,\n",
      "           0.0642,  0.0213, -0.0720, -0.0329,  0.1526, -0.0773,  0.0432,\n",
      "           0.0793, -0.1462, -0.1665, -0.0607, -0.0415, -0.0632, -0.0618,\n",
      "          -0.0552, -0.1318, -0.0993,  0.0094, -0.0619, -0.0205,  0.0508,\n",
      "           0.0393, -0.0019, -0.0285, -0.0061,  0.0619, -0.1216,  0.1028,\n",
      "           0.1269, -0.1068,  0.1416,  0.0713, -0.0813, -0.0605,  0.0767,\n",
      "          -0.0080,  0.0578,  0.1448,  0.0699,  0.0031,  0.0973,  0.1444,\n",
      "           0.0250,  0.1759, -0.0219,  0.1220, -0.1017,  0.0490, -0.0984,\n",
      "          -0.1427, -0.0508,  0.1050, -0.0277,  0.0319,  0.0289, -0.0095,\n",
      "          -0.1026,  0.0471, -0.0897, -0.0316,  0.0555, -0.0123, -0.1017,\n",
      "          -0.0641, -0.0008, -0.1350,  0.0511,  0.0547,  0.0171,  0.0648,\n",
      "          -0.0455, -0.0268, -0.0349, -0.1464, -0.0006,  0.0064,  0.0656,\n",
      "          -0.0232,  0.0373, -0.0067, -0.0121,  0.0796, -0.0941,  0.1618,\n",
      "           0.2307,  0.2180, -0.1031,  0.1781, -0.0702, -0.0571,  0.1785,\n",
      "           0.0672,  0.0086,  0.0768]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.0268, -0.2106,  0.1042,  0.1383,  0.0174,  0.1839, -0.0008,\n",
      "          -0.0103, -0.1508,  0.0373, -0.0048, -0.0191, -0.0113,  0.0747,\n",
      "          -0.0632, -0.1381,  0.0075, -0.0302, -0.0144,  0.0009, -0.1267,\n",
      "           0.0281, -0.2030,  0.0571, -0.0218,  0.0960,  0.0935,  0.0830,\n",
      "           0.1337, -0.1647, -0.0534,  0.1093,  0.2263, -0.0180,  0.0212,\n",
      "           0.1232,  0.0300, -0.0530, -0.0789, -0.0000, -0.1037,  0.3054,\n",
      "           0.0826, -0.0041,  0.0697,  0.0104,  0.0230, -0.0873,  0.0913,\n",
      "           0.0563, -0.0206,  0.1200,  0.0542,  0.0790,  0.1893, -0.0983,\n",
      "           0.0793, -0.0291, -0.0676,  0.0210,  0.0905,  0.0293,  0.0673,\n",
      "           0.0648, -0.1881, -0.0948, -0.0856, -0.0080, -0.0434,  0.0873,\n",
      "          -0.0206, -0.0888, -0.0359, -0.1325, -0.0557,  0.0130, -0.0418,\n",
      "           0.1379,  0.0911, -0.1178, -0.1206,  0.1028, -0.0540,  0.0138,\n",
      "           0.0752, -0.1377,  0.1680,  0.0000, -0.0720, -0.1704,  0.1663,\n",
      "          -0.0039,  0.0787,  0.1083, -0.0777, -0.0433,  0.0875,  0.0660,\n",
      "           0.2049,  0.1962, -0.0092,  0.1397, -0.1464, -0.0802, -0.0776,\n",
      "          -0.0657,  0.0763,  0.0474,  0.1547, -0.0120, -0.1116, -0.0301,\n",
      "           0.0241,  0.0755,  0.0238, -0.1661, -0.0504, -0.0223, -0.1622,\n",
      "          -0.0211,  0.1315, -0.0501,  0.0331, -0.0220, -0.0691,  0.1033,\n",
      "          -0.0625,  0.1136, -0.0355, -0.0527,  0.1507, -0.0102,  0.1167,\n",
      "          -0.0665, -0.0549,  0.0208, -0.0020,  0.0330, -0.1219,  0.1656,\n",
      "           0.1269,  0.2485, -0.0476,  0.2119, -0.1516, -0.1421, -0.0044,\n",
      "           0.0075,  0.0482,  0.0380]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.0787, -0.0650, -0.0781,  0.1410,  0.0010,  0.2030,  0.0812,\n",
      "          -0.0275, -0.0581,  0.0599,  0.0435, -0.0310,  0.0739,  0.0944,\n",
      "          -0.0041, -0.1101,  0.1330, -0.0214,  0.0404,  0.0736, -0.0921,\n",
      "           0.0827, -0.1763,  0.1014, -0.0146,  0.1060,  0.0998,  0.0834,\n",
      "           0.1538, -0.1503,  0.0265,  0.0438,  0.2694,  0.0378,  0.0879,\n",
      "           0.1389,  0.0488,  0.0717, -0.1325, -0.0209,  0.0027,  0.1461,\n",
      "          -0.0261,  0.0308,  0.1020, -0.0036, -0.0270, -0.0788,  0.1155,\n",
      "           0.0365,  0.0185,  0.1497,  0.1018,  0.0191,  0.0723, -0.0656,\n",
      "           0.0730, -0.1330, -0.1308,  0.0479,  0.0592, -0.0049,  0.0526,\n",
      "           0.1250, -0.0398, -0.1370, -0.0322,  0.0193,  0.0152, -0.0062,\n",
      "          -0.0421, -0.1039, -0.0415, -0.0689, -0.1112, -0.0105, -0.0027,\n",
      "           0.1283,  0.1159, -0.1042, -0.0760,  0.0849, -0.0493,  0.0586,\n",
      "           0.0230, -0.1822,  0.0589,  0.0598,  0.0485, -0.1040, -0.0423,\n",
      "           0.0311,  0.1158,  0.0637,  0.0097, -0.0486,  0.0690,  0.0899,\n",
      "           0.0147,  0.1439,  0.0210,  0.1865, -0.0900, -0.0292, -0.1074,\n",
      "          -0.0482,  0.0758,  0.0659,  0.0738,  0.0188,  0.0434, -0.1328,\n",
      "           0.1089,  0.1204,  0.0303, -0.0698, -0.0392, -0.0431, -0.1250,\n",
      "          -0.1253,  0.0773, -0.1334,  0.0414, -0.1464,  0.0040,  0.0479,\n",
      "          -0.1363,  0.0576,  0.0100, -0.0396,  0.1477, -0.0262,  0.1242,\n",
      "           0.0264, -0.0168, -0.0118,  0.0967,  0.0599, -0.1218,  0.1283,\n",
      "           0.2096,  0.2578, -0.0217,  0.1721, -0.0704, -0.1481,  0.0410,\n",
      "          -0.0351,  0.0247, -0.0301]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.1774, -0.0079, -0.0452,  0.1380,  0.1076,  0.1235, -0.0562,\n",
      "          -0.0711, -0.0348,  0.0631,  0.0772, -0.1421,  0.1673,  0.1096,\n",
      "          -0.0440, -0.0257,  0.0712,  0.0964, -0.0774,  0.1366,  0.0185,\n",
      "           0.0528, -0.1724,  0.2528,  0.0689, -0.0068,  0.0522,  0.1086,\n",
      "           0.2092, -0.1160,  0.0482, -0.0473,  0.2168,  0.0492,  0.0185,\n",
      "           0.0940,  0.0334,  0.1139, -0.1275,  0.0414,  0.0896,  0.1352,\n",
      "          -0.0476,  0.1288,  0.0799, -0.0189,  0.0900, -0.0319,  0.1659,\n",
      "          -0.0129, -0.1025,  0.1215,  0.0659, -0.0627,  0.0345, -0.1069,\n",
      "           0.1171, -0.0349, -0.1578, -0.1049,  0.1072, -0.0833, -0.0090,\n",
      "           0.0245, -0.1458, -0.1105, -0.1245, -0.0301, -0.0611, -0.0324,\n",
      "          -0.0691, -0.0428, -0.1109,  0.0275, -0.1693, -0.0305, -0.0559,\n",
      "           0.0318, -0.0077,  0.0151, -0.0082,  0.1709,  0.0282,  0.1025,\n",
      "          -0.1021, -0.1903, -0.0114, -0.0710,  0.0121,  0.0375, -0.0179,\n",
      "          -0.0204,  0.0657,  0.0791, -0.0581,  0.0314,  0.0356,  0.1388,\n",
      "           0.0133,  0.1731,  0.1157, -0.0275,  0.1197, -0.0642, -0.1157,\n",
      "          -0.1138,  0.0582,  0.0814, -0.0371,  0.0064,  0.1196, -0.0088,\n",
      "           0.2059, -0.0596, -0.0564, -0.0374, -0.0309,  0.0411, -0.0784,\n",
      "          -0.1574,  0.0971, -0.1997,  0.1261, -0.0669, -0.0814,  0.0528,\n",
      "          -0.2366, -0.0381,  0.0477,  0.0077,  0.2067, -0.0059,  0.1064,\n",
      "           0.0413,  0.0107,  0.0785,  0.0975,  0.0199, -0.0498,  0.2225,\n",
      "           0.2590,  0.1607,  0.0550,  0.0072, -0.0331, -0.1931, -0.0458,\n",
      "           0.0632,  0.0452,  0.1190]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.0877, -0.0555,  0.0104,  0.1494,  0.1117,  0.0223, -0.0735,\n",
      "          -0.0152, -0.0717,  0.0482,  0.1062, -0.0113,  0.2132,  0.0637,\n",
      "          -0.1237, -0.0072,  0.0630,  0.0325, -0.1815,  0.0739, -0.0232,\n",
      "          -0.0861, -0.1079,  0.2388,  0.1131, -0.0428,  0.1528,  0.0784,\n",
      "           0.1802, -0.2020, -0.0304, -0.1266,  0.2319,  0.0201, -0.0557,\n",
      "           0.1284,  0.1534,  0.0059,  0.1011,  0.1248, -0.0135,  0.1971,\n",
      "          -0.0253,  0.1948,  0.1011, -0.0686,  0.1591, -0.0011,  0.0731,\n",
      "           0.0070, -0.0904,  0.1093,  0.0281, -0.0255, -0.0067, -0.0877,\n",
      "           0.0148, -0.0032, -0.2733, -0.1446,  0.0451, -0.0766,  0.0323,\n",
      "           0.0377, -0.1785, -0.0024, -0.1158, -0.0113, -0.0987, -0.1834,\n",
      "          -0.1288,  0.0069, -0.0057, -0.0625, -0.2093, -0.1330,  0.0465,\n",
      "           0.0462,  0.0438, -0.0083, -0.0844,  0.2002,  0.0615,  0.1478,\n",
      "          -0.1215, -0.2297, -0.0868, -0.0988,  0.0081, -0.0091, -0.1042,\n",
      "           0.0727,  0.0872, -0.0357, -0.2225,  0.0024,  0.1447,  0.0722,\n",
      "           0.0790,  0.1900,  0.0551, -0.0949, -0.0785, -0.1386, -0.0787,\n",
      "          -0.1043,  0.0159,  0.0415, -0.1979,  0.0030, -0.0297,  0.0164,\n",
      "           0.1348, -0.0836,  0.0955, -0.0772, -0.1127,  0.1185, -0.0927,\n",
      "          -0.0906,  0.0828, -0.2083,  0.0861, -0.1315, -0.0368,  0.1207,\n",
      "          -0.0617, -0.0883,  0.0550,  0.1138,  0.0960,  0.1198,  0.1528,\n",
      "          -0.1208,  0.0055,  0.0255,  0.1005,  0.1254, -0.0132,  0.2296,\n",
      "           0.2159,  0.1438,  0.1097,  0.0606, -0.0227, -0.2605,  0.0722,\n",
      "           0.0897,  0.1127,  0.2397]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.1213, -0.1094,  0.0388,  0.2640,  0.1182,  0.0365, -0.1133,\n",
      "           0.1300, -0.0066,  0.1212,  0.1108,  0.0308,  0.1486, -0.0333,\n",
      "          -0.1562,  0.0422,  0.0309, -0.0131, -0.1390,  0.0928, -0.0694,\n",
      "          -0.0427, -0.0506,  0.1662,  0.1340, -0.0308,  0.1415,  0.0804,\n",
      "           0.2450, -0.1689, -0.0765, -0.1087,  0.2111,  0.1971, -0.0420,\n",
      "           0.1157,  0.1205,  0.0950, -0.1076,  0.1106, -0.0373,  0.1476,\n",
      "           0.0230, -0.0286,  0.1071, -0.0482,  0.1241,  0.0644,  0.0395,\n",
      "          -0.0746, -0.0890,  0.1119, -0.0360, -0.0621,  0.0740, -0.1923,\n",
      "          -0.0816,  0.0377, -0.0739, -0.0181,  0.1458, -0.0842,  0.0658,\n",
      "          -0.0618, -0.1914, -0.0650, -0.1439, -0.0602, -0.1168, -0.1186,\n",
      "          -0.0018, -0.1651, -0.0961,  0.0400, -0.1724, -0.1797,  0.0212,\n",
      "           0.0255, -0.0031, -0.1355, -0.1569,  0.2650,  0.0217,  0.1132,\n",
      "          -0.0816, -0.1215,  0.0411, -0.0535, -0.0763, -0.0768, -0.0246,\n",
      "           0.0502,  0.0189, -0.0417,  0.0012,  0.0151,  0.0880,  0.1135,\n",
      "           0.0755,  0.2613,  0.0230, -0.0219, -0.0954, -0.1203, -0.1071,\n",
      "          -0.1202,  0.0973,  0.0280, -0.1970, -0.0101, -0.0079,  0.1479,\n",
      "           0.0494, -0.0780,  0.0025, -0.0339, -0.0375,  0.0057, -0.1733,\n",
      "          -0.1155,  0.0857, -0.2042,  0.0196, -0.0171, -0.0430, -0.0134,\n",
      "          -0.1040, -0.1455,  0.0129,  0.0471,  0.1462,  0.0633,  0.1087,\n",
      "          -0.0291,  0.0216,  0.0974,  0.0709,  0.1140, -0.0866,  0.2267,\n",
      "           0.3986,  0.2394,  0.0872,  0.0263, -0.0623, -0.3026,  0.1097,\n",
      "           0.1811,  0.0438,  0.2032]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.0365, -0.0547, -0.0486,  0.1707,  0.0985,  0.1645,  0.0079,\n",
      "           0.0901, -0.0106,  0.1089,  0.1171,  0.0448,  0.1558,  0.1500,\n",
      "          -0.1281, -0.0296,  0.1578,  0.0199, -0.0512,  0.0647, -0.0816,\n",
      "          -0.0483, -0.0471,  0.2169,  0.0613, -0.0801,  0.1372,  0.0654,\n",
      "           0.1304, -0.1666,  0.0647,  0.0232,  0.1915,  0.1725,  0.0462,\n",
      "           0.0204,  0.0395,  0.1203, -0.0367,  0.0227,  0.0690,  0.1234,\n",
      "          -0.1212,  0.1059,  0.0373, -0.0044,  0.0503, -0.0084,  0.1123,\n",
      "          -0.0174,  0.0303,  0.1812, -0.1043,  0.0170, -0.0268, -0.1703,\n",
      "          -0.0633,  0.0532,  0.0033,  0.0788,  0.0847, -0.1214,  0.0342,\n",
      "          -0.0654, -0.0636, -0.2013, -0.1060, -0.0745, -0.1038, -0.1557,\n",
      "           0.0029, -0.0926, -0.1556,  0.0180, -0.0882, -0.1470, -0.0200,\n",
      "           0.0145, -0.1045, -0.1766, -0.1029,  0.1864, -0.1557,  0.0719,\n",
      "          -0.0629, -0.1237,  0.0773,  0.1512, -0.0929,  0.0121,  0.0071,\n",
      "           0.0081,  0.0135, -0.0525, -0.0463,  0.0510, -0.0999, -0.1006,\n",
      "           0.0658,  0.2792, -0.0479,  0.1782,  0.0204, -0.0932, -0.1654,\n",
      "          -0.1307,  0.0064,  0.0772, -0.0743,  0.0117, -0.1338,  0.0281,\n",
      "           0.1828,  0.0198, -0.0435, -0.0708, -0.1066, -0.0458, -0.1306,\n",
      "          -0.1054,  0.0303, -0.1896,  0.0786, -0.1223,  0.0035, -0.0618,\n",
      "          -0.0343, -0.0905, -0.0999, -0.0025,  0.1131,  0.0061,  0.1297,\n",
      "           0.0821,  0.0889,  0.1133,  0.1171, -0.0311, -0.1835,  0.2003,\n",
      "           0.2407,  0.1945,  0.0433, -0.0732, -0.0330, -0.1668,  0.0392,\n",
      "           0.1509,  0.0298,  0.1187]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.0442, -0.1475, -0.0382,  0.1867,  0.1181,  0.1266,  0.0729,\n",
      "           0.1089, -0.0606,  0.1653,  0.0473, -0.0286,  0.1355,  0.0799,\n",
      "          -0.0894, -0.1127,  0.1315,  0.1069, -0.0973,  0.1080, -0.1300,\n",
      "           0.0010, -0.0276,  0.1813, -0.0898, -0.0321,  0.1360,  0.0179,\n",
      "           0.1589, -0.1956,  0.0478,  0.0635,  0.1323,  0.1029,  0.0818,\n",
      "           0.0867, -0.0111,  0.0732, -0.1488, -0.0608,  0.0407,  0.2158,\n",
      "          -0.1138,  0.0131,  0.0207, -0.0110, -0.0382,  0.0876,  0.1610,\n",
      "          -0.0576, -0.0699,  0.1436, -0.0527,  0.0480,  0.0313, -0.1090,\n",
      "           0.0255, -0.0234,  0.0226,  0.0728,  0.1165, -0.1299, -0.0256,\n",
      "           0.0369, -0.0722, -0.1727, -0.0607,  0.0029, -0.0080, -0.1322,\n",
      "           0.0193, -0.0763,  0.0570, -0.0089, -0.0830, -0.0358, -0.0463,\n",
      "           0.1347, -0.0231, -0.1074, -0.1050,  0.1966, -0.1685,  0.1286,\n",
      "           0.0439, -0.0401,  0.0345,  0.1293, -0.0166,  0.0588,  0.0288,\n",
      "           0.0659,  0.0530,  0.0748, -0.0737,  0.0996, -0.0250, -0.0370,\n",
      "           0.0263,  0.1502,  0.0255,  0.1327,  0.0311, -0.1038, -0.0912,\n",
      "          -0.1659,  0.0903,  0.2167, -0.0558,  0.1197, -0.0276,  0.0213,\n",
      "           0.1372,  0.0409, -0.0850, -0.1119, -0.1084, -0.1429, -0.1646,\n",
      "          -0.1947,  0.0304, -0.1932, -0.0368, -0.1057, -0.0562, -0.0921,\n",
      "          -0.1087, -0.0486,  0.0010,  0.0568,  0.1502, -0.0209,  0.0791,\n",
      "           0.0712,  0.0286,  0.0695,  0.0473,  0.0144, -0.1289,  0.2429,\n",
      "           0.1460,  0.2346,  0.0898,  0.0139, -0.0139, -0.1208,  0.0090,\n",
      "           0.0700, -0.0320,  0.0585]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.0430, -0.1460, -0.0659,  0.1442, -0.0233,  0.1876,  0.0651,\n",
      "           0.0615, -0.0550,  0.1090,  0.1424, -0.0640,  0.1589,  0.1309,\n",
      "          -0.0281, -0.0178,  0.1943,  0.0886, -0.0316,  0.0420, -0.2071,\n",
      "           0.0016, -0.0695,  0.1206,  0.0239, -0.0210,  0.1102,  0.0205,\n",
      "           0.1432, -0.1954,  0.1447,  0.1433,  0.1077, -0.0692,  0.0206,\n",
      "           0.1087,  0.0288,  0.0770, -0.1498, -0.0236, -0.0448, -0.0401,\n",
      "          -0.1543, -0.0594,  0.0580,  0.0015, -0.0395,  0.0675,  0.1502,\n",
      "           0.0198, -0.0655,  0.1264, -0.0063,  0.0144,  0.0175,  0.0476,\n",
      "           0.1153, -0.0181,  0.0097,  0.0250,  0.0982, -0.1247,  0.0726,\n",
      "           0.1412,  0.0402, -0.2122, -0.0656, -0.0943,  0.0149, -0.0770,\n",
      "           0.0058, -0.1037, -0.1853,  0.0601, -0.0977,  0.0417, -0.0386,\n",
      "           0.1302, -0.0990, -0.0342, -0.0506,  0.0416, -0.1385,  0.1170,\n",
      "           0.0506, -0.0769,  0.0083,  0.1929,  0.0362,  0.0725,  0.0573,\n",
      "          -0.0048,  0.0676,  0.0508,  0.0389,  0.1475, -0.0450,  0.0171,\n",
      "          -0.0536,  0.1567, -0.0969,  0.1741,  0.0523, -0.0949, -0.0251,\n",
      "          -0.0718,  0.0203,  0.1812,  0.0052,  0.0925, -0.0013, -0.1025,\n",
      "           0.0569,  0.0637, -0.1442, -0.0386, -0.0467, -0.1019, -0.1266,\n",
      "          -0.1215, -0.0532, -0.2024,  0.0648, -0.0469, -0.1184,  0.0809,\n",
      "          -0.1224, -0.0331, -0.0451, -0.0667,  0.1133, -0.0152,  0.1204,\n",
      "           0.0952,  0.1261,  0.0701,  0.1503,  0.0314, -0.1769,  0.1629,\n",
      "           0.1228,  0.1783, -0.0538, -0.0430, -0.0610,  0.0122,  0.0086,\n",
      "           0.0021,  0.0878,  0.0252]]], grad_fn=<CatBackward>)\n",
      "tensor([[[-0.0885, -0.1808, -0.0818,  0.0464, -0.1877,  0.2220,  0.1200,\n",
      "           0.0378, -0.0973,  0.0506,  0.1995, -0.0240, -0.0239, -0.0172,\n",
      "           0.0525, -0.1600,  0.0514, -0.0495, -0.0168,  0.0008, -0.2201,\n",
      "           0.0798, -0.0993,  0.1090,  0.0018,  0.0578,  0.1866,  0.0373,\n",
      "           0.1165, -0.1619,  0.0487,  0.0289,  0.0582, -0.0910,  0.0648,\n",
      "           0.0072,  0.0782,  0.1799, -0.1496, -0.0860,  0.0022,  0.0573,\n",
      "          -0.1281, -0.1302, -0.0720,  0.1914,  0.0898,  0.0261,  0.0550,\n",
      "           0.0479, -0.0466,  0.0766, -0.0610, -0.0708, -0.0200,  0.0123,\n",
      "           0.2183, -0.0950,  0.0493,  0.0716,  0.0636, -0.1143,  0.0713,\n",
      "           0.0456, -0.1225, -0.1934, -0.1221, -0.1111,  0.0206,  0.0147,\n",
      "          -0.0592, -0.0377, -0.1773, -0.0368, -0.0972, -0.0828,  0.0270,\n",
      "          -0.0002, -0.0997, -0.0364,  0.0802, -0.0868, -0.1619,  0.1361,\n",
      "           0.1491, -0.0806,  0.0107,  0.0694, -0.1012,  0.0171,  0.0728,\n",
      "          -0.0861, -0.0902, -0.0114,  0.0724,  0.1916,  0.0234,  0.1081,\n",
      "          -0.0046,  0.1308, -0.2017,  0.2158, -0.0415, -0.0147, -0.0513,\n",
      "          -0.0787, -0.0256,  0.2006,  0.0135,  0.0482,  0.0149, -0.0644,\n",
      "          -0.0746,  0.1048, -0.2211, -0.0976, -0.0418, -0.1166, -0.0039,\n",
      "          -0.0239, -0.0463, -0.1929, -0.0405,  0.0016,  0.0463,  0.0434,\n",
      "          -0.0551, -0.0077, -0.0177,  0.0058,  0.0765, -0.0189,  0.0559,\n",
      "          -0.0660,  0.0640,  0.0826,  0.0982,  0.0418, -0.1049,  0.1215,\n",
      "           0.2227,  0.2938, -0.1448, -0.0045, -0.1735,  0.0151,  0.1577,\n",
      "           0.0445,  0.0650,  0.1569]]], grad_fn=<CatBackward>)\n",
      "tensor([[[-0.0170, -0.1877, -0.1178,  0.0003,  0.0183,  0.1513,  0.0513,\n",
      "           0.0654, -0.2034,  0.0554,  0.1667,  0.0394, -0.0479,  0.1153,\n",
      "          -0.0783, -0.0241,  0.1659, -0.1008,  0.0222, -0.0027, -0.0298,\n",
      "           0.0572, -0.1111,  0.1717, -0.0126,  0.0686,  0.1291,  0.1413,\n",
      "           0.1503, -0.1377, -0.0474,  0.1184,  0.1166, -0.1284,  0.1702,\n",
      "           0.0481,  0.2052, -0.0007,  0.0610, -0.1057, -0.0667,  0.0160,\n",
      "          -0.0328, -0.0402, -0.0594,  0.0715,  0.0558,  0.0707,  0.0315,\n",
      "           0.0475, -0.0983,  0.1428,  0.0186,  0.0203,  0.0599,  0.0380,\n",
      "           0.0379, -0.0867, -0.1020, -0.0536,  0.2141, -0.0984,  0.1136,\n",
      "           0.1238,  0.0316, -0.0481, -0.1272,  0.0493, -0.0810,  0.0626,\n",
      "          -0.0919,  0.0560, -0.1893, -0.0772, -0.0521,  0.0372, -0.0034,\n",
      "           0.0228,  0.0212, -0.0267,  0.0091, -0.2557, -0.0907,  0.0528,\n",
      "           0.0566, -0.1528,  0.0130,  0.0676, -0.1992, -0.0114, -0.0691,\n",
      "           0.0507, -0.0645,  0.0306, -0.0712,  0.3413,  0.1525,  0.0601,\n",
      "           0.0658,  0.2137, -0.0904,  0.2560, -0.1544,  0.0084, -0.0164,\n",
      "          -0.0421, -0.0381,  0.0098,  0.0478, -0.0145, -0.0628, -0.0768,\n",
      "           0.0972,  0.1655, -0.0568, -0.1389, -0.0583, -0.0829, -0.0067,\n",
      "           0.0196,  0.0053, -0.1169, -0.0862, -0.0289,  0.0584, -0.0215,\n",
      "          -0.0784, -0.0126, -0.0868, -0.1501,  0.0523, -0.0474,  0.0449,\n",
      "          -0.1279,  0.0720,  0.0896,  0.0267,  0.0217,  0.0156,  0.2127,\n",
      "           0.1443,  0.1259, -0.2224, -0.0607, -0.1362, -0.0893,  0.1331,\n",
      "          -0.0169,  0.0803,  0.1543]]], grad_fn=<CatBackward>)\n",
      "tensor([[[-0.1075, -0.2143,  0.0213,  0.0977,  0.0553,  0.1173, -0.0191,\n",
      "          -0.0794, -0.1997,  0.1311,  0.1644, -0.0393, -0.1069, -0.0050,\n",
      "          -0.0766, -0.0203,  0.0982, -0.0172,  0.0102,  0.0279, -0.0988,\n",
      "          -0.0225, -0.1570,  0.2579,  0.0040,  0.0106,  0.1151,  0.1713,\n",
      "           0.1717, -0.0543,  0.0140, -0.0189,  0.1801, -0.0383,  0.0390,\n",
      "          -0.0019,  0.0560, -0.0413, -0.0365, -0.1436, -0.1045, -0.0126,\n",
      "          -0.1126, -0.0383,  0.0394,  0.0593,  0.1710,  0.0312,  0.0816,\n",
      "          -0.0831,  0.0360,  0.1029,  0.1137, -0.0344, -0.0153, -0.0696,\n",
      "           0.0700, -0.0553, -0.1486, -0.0395,  0.1063, -0.0637,  0.0721,\n",
      "           0.0413, -0.0494, -0.1220, -0.1062,  0.0214, -0.1629,  0.0213,\n",
      "          -0.0618, -0.0575, -0.1407, -0.0402, -0.0724,  0.0571, -0.0734,\n",
      "           0.0710,  0.0516, -0.0874,  0.0524, -0.0438, -0.0730,  0.1295,\n",
      "           0.0034, -0.0999, -0.0619,  0.0623, -0.1539, -0.0506,  0.0416,\n",
      "           0.0369, -0.0879,  0.0400, -0.0634,  0.2540,  0.1039,  0.0351,\n",
      "           0.0984,  0.0140, -0.0990,  0.1511, -0.0299,  0.0036, -0.1194,\n",
      "          -0.1164, -0.0241,  0.1727,  0.0499,  0.0280, -0.0810,  0.0295,\n",
      "           0.0606,  0.0807, -0.1393, -0.1385, -0.1447, -0.0109, -0.0123,\n",
      "          -0.0886,  0.1134, -0.1023, -0.0515, -0.0121,  0.1953,  0.0260,\n",
      "          -0.0217, -0.0371,  0.0303, -0.1191,  0.0432,  0.0125,  0.1291,\n",
      "          -0.1690,  0.0348,  0.0729,  0.0663, -0.0208,  0.1404,  0.2234,\n",
      "           0.2767,  0.1904, -0.0431, -0.0892, -0.1113, -0.1770,  0.0324,\n",
      "          -0.0262, -0.0097,  0.2376]]], grad_fn=<CatBackward>)\n",
      "tensor([[[-0.0661, -0.1127, -0.0551,  0.1306,  0.0601,  0.2238,  0.0529,\n",
      "          -0.0211, -0.1342,  0.1040,  0.1658,  0.0103,  0.0397,  0.1530,\n",
      "          -0.1009, -0.0521,  0.2113,  0.0284,  0.0390,  0.0099, -0.0825,\n",
      "          -0.0125, -0.0786,  0.2475, -0.0249, -0.0597,  0.1205,  0.0806,\n",
      "           0.1160, -0.1215,  0.0966,  0.1077,  0.1965,  0.0748,  0.0989,\n",
      "          -0.0751,  0.0464,  0.0351,  0.0015, -0.0635,  0.0339,  0.0501,\n",
      "          -0.1948,  0.1038,  0.0403,  0.0584,  0.0560, -0.0324,  0.1321,\n",
      "          -0.0016,  0.1344,  0.1755, -0.0477,  0.0143, -0.0748, -0.1168,\n",
      "           0.0002, -0.0050, -0.0360,  0.0655,  0.0793, -0.1052,  0.0862,\n",
      "          -0.0017, -0.0305, -0.2351, -0.1013, -0.0626, -0.1217, -0.1268,\n",
      "          -0.0202, -0.0704, -0.1601, -0.0193, -0.0507, -0.0293, -0.1245,\n",
      "           0.0241, -0.0791, -0.1319,  0.0027,  0.0334, -0.2004,  0.0739,\n",
      "          -0.0240, -0.1134,  0.0541,  0.2204, -0.1393,  0.0527,  0.0386,\n",
      "          -0.0195, -0.0748,  0.0005, -0.0686,  0.1201, -0.0818, -0.1434,\n",
      "           0.0647,  0.1314, -0.1318,  0.2673,  0.0645, -0.0296, -0.1636,\n",
      "          -0.1409, -0.0807,  0.1510,  0.0627,  0.0305, -0.1670, -0.0178,\n",
      "           0.2027,  0.0751, -0.0906, -0.1066, -0.1295, -0.0394, -0.0537,\n",
      "          -0.0732,  0.0486, -0.1241,  0.0446, -0.1189,  0.0988, -0.0553,\n",
      "           0.0348, -0.0548, -0.0954, -0.0960,  0.0639, -0.0144,  0.1461,\n",
      "          -0.0035,  0.0887,  0.1045,  0.0898, -0.0900, -0.0462,  0.1788,\n",
      "           0.2056,  0.1572, -0.0483, -0.0774, -0.0679, -0.1357, -0.0012,\n",
      "           0.0575, -0.0146,  0.1153]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.0263, -0.1697, -0.1168,  0.0263,  0.0725,  0.1207,  0.0274,\n",
      "           0.0411, -0.2134,  0.0827,  0.1748,  0.0466, -0.0129,  0.2027,\n",
      "          -0.1115,  0.0073,  0.2440, -0.0609,  0.0620,  0.0035,  0.0078,\n",
      "           0.0133, -0.0907,  0.2119, -0.0261,  0.0222,  0.0897,  0.1443,\n",
      "           0.1513, -0.0803, -0.0196,  0.1458,  0.1724,  0.0469,  0.1666,\n",
      "           0.0130,  0.1901, -0.0366,  0.1442, -0.1186, -0.0561,  0.0154,\n",
      "          -0.0617,  0.0586, -0.0208, -0.0091,  0.0427,  0.0474,  0.0816,\n",
      "           0.0043,  0.0211,  0.1919,  0.0249,  0.0864,  0.0326, -0.0454,\n",
      "          -0.0550, -0.0509, -0.1362, -0.0494,  0.2421, -0.0770,  0.1202,\n",
      "           0.0964,  0.0813, -0.0833, -0.1282,  0.0797, -0.1535,  0.0122,\n",
      "          -0.0589,  0.0512, -0.2072, -0.0620, -0.0331,  0.0574, -0.0526,\n",
      "           0.0557,  0.0385, -0.0901, -0.0382, -0.1863, -0.0937, -0.0045,\n",
      "          -0.0436, -0.1681,  0.0382,  0.1598, -0.2019,  0.0045, -0.0752,\n",
      "           0.0636, -0.0266,  0.0396, -0.1738,  0.3388,  0.0938, -0.0830,\n",
      "           0.0965,  0.2061, -0.0844,  0.2688, -0.0882,  0.0014, -0.0495,\n",
      "          -0.0555, -0.0453,  0.0223,  0.1018, -0.0139, -0.1427, -0.0413,\n",
      "           0.1998,  0.1342, -0.0187, -0.1548, -0.1373, -0.0638, -0.0339,\n",
      "           0.0075,  0.0791, -0.0676, -0.0273, -0.0699,  0.0648, -0.0834,\n",
      "          -0.0431, -0.0357, -0.1182, -0.1910,  0.0698, -0.0317,  0.1117,\n",
      "          -0.0882,  0.0613,  0.1007,  0.0030, -0.0179,  0.0509,  0.2475,\n",
      "           0.1380,  0.0980, -0.1570, -0.0823, -0.0705, -0.1970,  0.0861,\n",
      "          -0.0571,  0.0534,  0.1334]]], grad_fn=<CatBackward>)\n",
      "tensor([[[-0.0649, -0.2496, -0.0290,  0.0674,  0.0041,  0.0927,  0.0443,\n",
      "          -0.0802, -0.2211,  0.2129,  0.1824,  0.0690, -0.1202,  0.0435,\n",
      "          -0.1343,  0.0584,  0.0475, -0.0797,  0.0246,  0.0705, -0.0313,\n",
      "           0.0627, -0.1344,  0.2180, -0.0389,  0.0285,  0.1933,  0.1680,\n",
      "           0.0462, -0.0314, -0.0018,  0.0088, -0.0067,  0.1604, -0.0281,\n",
      "           0.0116,  0.0617, -0.0826,  0.0955, -0.0899, -0.0960, -0.0338,\n",
      "          -0.0320, -0.0010,  0.1359,  0.0656,  0.1449, -0.0582,  0.0356,\n",
      "           0.0004,  0.0193,  0.2270,  0.0318,  0.0959,  0.1118, -0.1013,\n",
      "          -0.0474,  0.0417, -0.2101,  0.0113,  0.0268, -0.1302,  0.0518,\n",
      "           0.0407, -0.1028, -0.0939, -0.0542,  0.1610, -0.0924, -0.0298,\n",
      "           0.0068,  0.1537, -0.1920, -0.1522,  0.1315,  0.1260, -0.1127,\n",
      "           0.1593, -0.0451,  0.0014,  0.0292, -0.1004,  0.0302,  0.1595,\n",
      "          -0.1201, -0.1072, -0.0795,  0.0764, -0.0809,  0.0213,  0.0404,\n",
      "           0.0643,  0.0303,  0.1041, -0.1319,  0.2257,  0.0836, -0.0383,\n",
      "           0.0689,  0.0761, -0.1550,  0.0758,  0.0426, -0.0058, -0.0843,\n",
      "          -0.0273,  0.0208,  0.1380,  0.0539,  0.1523, -0.1236,  0.0248,\n",
      "          -0.0023, -0.0425,  0.1584, -0.0938, -0.0550, -0.0260, -0.0274,\n",
      "           0.0600,  0.0118, -0.0676, -0.0778, -0.0718, -0.0385, -0.1072,\n",
      "           0.0631, -0.0132, -0.0365, -0.0677,  0.0782,  0.0189,  0.1982,\n",
      "          -0.0825,  0.0709,  0.1005,  0.0364,  0.0469,  0.1940,  0.2923,\n",
      "           0.2002,  0.1983, -0.1307,  0.0202, -0.0568, -0.2705,  0.0279,\n",
      "          -0.0965,  0.0722,  0.0576]]], grad_fn=<CatBackward>)\n",
      "tensor([[[-0.0438, -0.1563, -0.0673,  0.0936,  0.0300,  0.2337,  0.0643,\n",
      "          -0.0368, -0.1447,  0.1682,  0.1679,  0.0446,  0.0078,  0.1792,\n",
      "          -0.1345,  0.0099,  0.1592, -0.0197,  0.0286,  0.0418, -0.0765,\n",
      "           0.0346, -0.0968,  0.2129, -0.0378, -0.0480,  0.1441,  0.0774,\n",
      "           0.0651, -0.1180,  0.0968,  0.1352,  0.1445,  0.1895,  0.0443,\n",
      "          -0.0345,  0.0567,  0.0388,  0.0325, -0.0472,  0.0385,  0.0338,\n",
      "          -0.1608,  0.1264,  0.0805,  0.0794,  0.0402, -0.0868,  0.1115,\n",
      "           0.0090,  0.1244,  0.2460, -0.0615,  0.0925, -0.0238, -0.1011,\n",
      "          -0.0357,  0.0542, -0.0241,  0.0894,  0.0313, -0.1398,  0.0658,\n",
      "           0.0003, -0.0302, -0.2339, -0.0803, -0.0104, -0.0803, -0.1366,\n",
      "           0.0198,  0.0059, -0.1927, -0.0601,  0.0674,  0.0204, -0.1390,\n",
      "           0.0646, -0.1242, -0.0871,  0.0061,  0.0037, -0.1544,  0.0779,\n",
      "          -0.0651, -0.1366,  0.0375,  0.2170, -0.0972,  0.0541,  0.0641,\n",
      "          -0.0273,  0.0164,  0.0528, -0.0971,  0.1295, -0.0911, -0.1541,\n",
      "           0.0371,  0.1833, -0.1454,  0.2548,  0.1067, -0.0183, -0.1444,\n",
      "          -0.0989, -0.0417,  0.1599,  0.0663,  0.0745, -0.1804, -0.0238,\n",
      "           0.1762,  0.0329,  0.0657, -0.1049, -0.0938, -0.0555, -0.0702,\n",
      "           0.0033, -0.0044, -0.1251,  0.0319, -0.1223, -0.0039, -0.1468,\n",
      "           0.0506, -0.0294, -0.1195, -0.0531,  0.0715, -0.0034,  0.1704,\n",
      "           0.0689,  0.1085,  0.1029,  0.0682, -0.0388,  0.0115,  0.1977,\n",
      "           0.1683,  0.2011, -0.1015, -0.0327, -0.0135, -0.1758, -0.0260,\n",
      "           0.0116,  0.0197,  0.0183]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.0461, -0.1901, -0.1186,  0.0014,  0.0654,  0.1211,  0.0286,\n",
      "           0.0361, -0.2129,  0.1214,  0.1789,  0.0551, -0.0414,  0.2127,\n",
      "          -0.1195,  0.0532,  0.2113, -0.0898,  0.0432,  0.0181, -0.0024,\n",
      "           0.0355, -0.1037,  0.1934, -0.0330,  0.0266,  0.0987,  0.1369,\n",
      "           0.1278, -0.0814, -0.0197,  0.1591,  0.1577,  0.1681,  0.1371,\n",
      "           0.0411,  0.1975, -0.0242,  0.1618, -0.1139, -0.0567,  0.0020,\n",
      "          -0.0452,  0.0696, -0.0031,  0.0179,  0.0370,  0.0160,  0.0761,\n",
      "           0.0013,  0.0130,  0.2287,  0.0241,  0.1399,  0.0547, -0.0277,\n",
      "          -0.0717, -0.0132, -0.1162, -0.0334,  0.1914, -0.0942,  0.1012,\n",
      "           0.0958,  0.0890, -0.0850, -0.1235,  0.1010, -0.1341,  0.0075,\n",
      "          -0.0286,  0.0781, -0.2374, -0.0819,  0.0326,  0.0678, -0.0536,\n",
      "           0.0716,  0.0016, -0.0715, -0.0282, -0.1968, -0.0574, -0.0022,\n",
      "          -0.0574, -0.1749,  0.0139,  0.1667, -0.1818, -0.0013, -0.0633,\n",
      "           0.0542,  0.0031,  0.0773, -0.1879,  0.3460,  0.0878, -0.0745,\n",
      "           0.0811,  0.2321, -0.0844,  0.2792, -0.0701,  0.0166, -0.0391,\n",
      "          -0.0440, -0.0258,  0.0279,  0.1081,  0.0081, -0.1507, -0.0455,\n",
      "           0.1867,  0.1055,  0.0620, -0.1573, -0.1118, -0.0781, -0.0383,\n",
      "           0.0397,  0.0473, -0.0716, -0.0362, -0.0600,  0.0349, -0.1274,\n",
      "          -0.0417, -0.0160, -0.1207, -0.1662,  0.0723, -0.0197,  0.1197,\n",
      "          -0.0350,  0.0738,  0.0985, -0.0135,  0.0070,  0.0790,  0.2529,\n",
      "           0.1164,  0.1090, -0.1846, -0.0711, -0.0300, -0.2391,  0.0688,\n",
      "          -0.0865,  0.0672,  0.0851]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.1269, -0.2069,  0.0002,  0.0901,  0.0315,  0.1103,  0.0262,\n",
      "          -0.1380, -0.1412,  0.0894,  0.1731,  0.0040, -0.1294,  0.0627,\n",
      "          -0.0009, -0.0365,  0.1729,  0.0296,  0.0865,  0.2455, -0.0323,\n",
      "          -0.0716, -0.2319,  0.2108,  0.0841,  0.0177,  0.2036,  0.1140,\n",
      "           0.1156, -0.1323, -0.0861,  0.2415,  0.1385,  0.1730,  0.1586,\n",
      "           0.0355,  0.0898,  0.0089,  0.0904, -0.1000, -0.0555, -0.0099,\n",
      "          -0.0235,  0.0347,  0.1396,  0.0245,  0.1041,  0.0355,  0.1248,\n",
      "          -0.2411,  0.0089,  0.1730,  0.0968,  0.0984,  0.0678,  0.0039,\n",
      "          -0.0268, -0.0665, -0.1261,  0.0395,  0.1567, -0.1595, -0.0007,\n",
      "           0.1427, -0.0370, -0.0246, -0.1194,  0.0199, -0.1657,  0.0214,\n",
      "          -0.0083, -0.0130, -0.2459, -0.1924,  0.0655,  0.0303, -0.0858,\n",
      "           0.2105,  0.0658, -0.0515, -0.1049,  0.0134,  0.0140,  0.1078,\n",
      "          -0.0853, -0.2177, -0.0195,  0.1381, -0.1542, -0.0032, -0.0705,\n",
      "           0.0554, -0.0763,  0.0443, -0.3469,  0.2796,  0.1580, -0.0750,\n",
      "           0.1396,  0.1579, -0.0937,  0.2961,  0.0482, -0.0436, -0.1011,\n",
      "          -0.1099,  0.0312,  0.1572,  0.0296, -0.1098, -0.1814, -0.0059,\n",
      "           0.0612,  0.0280, -0.0059, -0.1893, -0.1024,  0.0010, -0.0343,\n",
      "           0.0593, -0.1404,  0.0346, -0.0773, -0.1511,  0.1916, -0.0356,\n",
      "           0.0146,  0.1546, -0.2356, -0.0981,  0.1076, -0.0109,  0.1972,\n",
      "          -0.1095,  0.0545, -0.0143,  0.0308, -0.0631,  0.2259,  0.1822,\n",
      "           0.1355,  0.2332, -0.1184, -0.0599, -0.0632, -0.2690,  0.1371,\n",
      "          -0.0030, -0.0408,  0.0899]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.0441, -0.0895, -0.0667,  0.1225,  0.0298,  0.2167,  0.0827,\n",
      "          -0.0738, -0.1298,  0.0952,  0.1666,  0.0293,  0.0148,  0.1805,\n",
      "          -0.0490, -0.0581,  0.2511,  0.0390,  0.0649,  0.1491, -0.0415,\n",
      "          -0.0429, -0.1053,  0.2208, -0.0117, -0.0535,  0.1658,  0.0732,\n",
      "           0.0842, -0.1834,  0.0617,  0.1891,  0.2150,  0.1900,  0.1538,\n",
      "          -0.0304,  0.0613,  0.0528,  0.0276, -0.0431,  0.0677,  0.0479,\n",
      "          -0.1456,  0.1406,  0.0956,  0.0471,  0.0339, -0.0367,  0.1515,\n",
      "          -0.0908,  0.1111,  0.2069, -0.0574,  0.0942, -0.0278, -0.0788,\n",
      "          -0.0333, -0.0061, -0.0127,  0.1165,  0.0895, -0.1603,  0.0069,\n",
      "           0.0734, -0.0199, -0.2111, -0.1294, -0.0588, -0.1217, -0.1201,\n",
      "           0.0221, -0.0534, -0.2067, -0.0704,  0.0209, -0.0461, -0.1129,\n",
      "           0.1028, -0.0550, -0.1058, -0.1097,  0.0764, -0.1701,  0.0602,\n",
      "          -0.0713, -0.1516,  0.0607,  0.2111, -0.1174,  0.0525, -0.0117,\n",
      "          -0.0224, -0.0512,  0.0130, -0.1537,  0.1349, -0.0583, -0.1843,\n",
      "           0.0944,  0.2265, -0.1292,  0.3137,  0.1077, -0.0357, -0.1620,\n",
      "          -0.1400, -0.0417,  0.1969,  0.0432, -0.0398, -0.2248, -0.0468,\n",
      "           0.1985,  0.0438, -0.0085, -0.1266, -0.1280, -0.0380, -0.0692,\n",
      "          -0.0145, -0.0711, -0.0666,  0.0100, -0.1578,  0.1135, -0.1038,\n",
      "           0.0336,  0.0111, -0.1988, -0.0834,  0.1013, -0.0252,  0.1717,\n",
      "           0.0160,  0.1096,  0.0587,  0.0722, -0.1229,  0.0175,  0.1553,\n",
      "           0.1256,  0.1591, -0.1060, -0.0725, -0.0272, -0.1542,  0.0250,\n",
      "           0.0664, -0.0027,  0.0246]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.1338, -0.1817, -0.1911,  0.0910, -0.0558,  0.1441,  0.0459,\n",
      "          -0.0091, -0.1497,  0.0191,  0.1760,  0.0413, -0.0574,  0.0415,\n",
      "          -0.1187, -0.2208,  0.0826,  0.0128,  0.0793,  0.1244, -0.0094,\n",
      "           0.0919, -0.2331,  0.1977,  0.0356,  0.0968,  0.1784,  0.0464,\n",
      "           0.0402, -0.0969,  0.0509,  0.0980,  0.0555,  0.2609,  0.0660,\n",
      "           0.0211,  0.1187, -0.0736, -0.1018, -0.0792,  0.0625, -0.0119,\n",
      "          -0.0408,  0.1490,  0.1084,  0.0652, -0.0049, -0.0785,  0.1735,\n",
      "          -0.1073,  0.0306,  0.1786, -0.0076,  0.1043,  0.1050, -0.0706,\n",
      "           0.0844, -0.0929,  0.0121,  0.0125,  0.1415, -0.0772,  0.0231,\n",
      "          -0.0487, -0.0057, -0.2688, -0.1028,  0.0155, -0.0725,  0.0306,\n",
      "           0.0098, -0.0581, -0.2986, -0.0980, -0.0518,  0.1059, -0.0448,\n",
      "           0.0213, -0.0295, -0.0083, -0.0525, -0.0196, -0.1771,  0.1665,\n",
      "          -0.0349, -0.1632,  0.0803,  0.2159, -0.0835, -0.0201, -0.0595,\n",
      "          -0.0569, -0.1123,  0.0587, -0.0775,  0.2502, -0.0484, -0.0536,\n",
      "           0.0969,  0.2005, -0.0960, -0.0139,  0.1028, -0.1252, -0.2512,\n",
      "          -0.0984, -0.0419,  0.1480,  0.2126, -0.0620, -0.1435, -0.0110,\n",
      "           0.0280,  0.0206,  0.0452, -0.1117, -0.1499,  0.0411,  0.0191,\n",
      "          -0.0799, -0.0257, -0.1053, -0.0188, -0.0783,  0.0812, -0.0805,\n",
      "           0.1102,  0.1447, -0.1811, -0.1591,  0.1549,  0.0375,  0.0043,\n",
      "          -0.0080, -0.0246,  0.0682, -0.0288,  0.0359,  0.0113,  0.2378,\n",
      "           0.2049,  0.0476, -0.0811,  0.1124, -0.0029, -0.1821,  0.1069,\n",
      "           0.1411,  0.0725,  0.1857]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.2016, -0.2256, -0.0669,  0.0614, -0.1186,  0.2092,  0.0213,\n",
      "          -0.0823, -0.2578, -0.0067,  0.1529,  0.0509, -0.2074,  0.2346,\n",
      "           0.0295, -0.0327,  0.1138,  0.0028, -0.0440,  0.1604, -0.0045,\n",
      "           0.1240, -0.2673,  0.1542,  0.0766,  0.1215,  0.1611,  0.0836,\n",
      "           0.1215, -0.1581,  0.0316,  0.0761,  0.0527,  0.3927,  0.0354,\n",
      "           0.0528,  0.1930,  0.0562, -0.1364, -0.1369, -0.0489,  0.0158,\n",
      "           0.0819,  0.0961,  0.0794,  0.1134,  0.0498, -0.1788,  0.2535,\n",
      "          -0.0423,  0.1457,  0.1524,  0.0352,  0.1607,  0.1645, -0.0680,\n",
      "           0.0900, -0.2215, -0.0467,  0.0065,  0.1289, -0.1468, -0.0072,\n",
      "          -0.0026,  0.0372, -0.1125, -0.0679, -0.0275, -0.1304, -0.0825,\n",
      "          -0.0776, -0.1262, -0.3075, -0.1834, -0.0027,  0.0782, -0.1141,\n",
      "           0.2294,  0.0267, -0.0186, -0.0733,  0.0157, -0.1274,  0.1241,\n",
      "           0.0550, -0.2471,  0.0290, -0.0214, -0.1284,  0.0288,  0.0561,\n",
      "          -0.0284, -0.0125,  0.1041, -0.0782,  0.2233, -0.0127, -0.0922,\n",
      "           0.2219,  0.1312,  0.0317,  0.1257,  0.0529, -0.0569, -0.1076,\n",
      "          -0.0149, -0.0741,  0.1091,  0.1523,  0.0166, -0.2824, -0.1313,\n",
      "           0.0175,  0.0742,  0.0430, -0.1818, -0.1730, -0.0567, -0.0082,\n",
      "          -0.0239,  0.0684, -0.1009, -0.1904, -0.0812,  0.0359,  0.0198,\n",
      "           0.0692,  0.0495, -0.0710,  0.0367,  0.1256,  0.0624,  0.0919,\n",
      "          -0.0230, -0.0271,  0.0031,  0.0419,  0.1331,  0.1039,  0.2703,\n",
      "           0.2087,  0.1993, -0.0366,  0.1305, -0.0894, -0.2102,  0.1712,\n",
      "           0.1343,  0.0163,  0.2120]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.2365, -0.1289,  0.0591,  0.2626, -0.0239,  0.1890,  0.0459,\n",
      "          -0.1334, -0.3355,  0.1002,  0.0336, -0.0014, -0.1706,  0.2405,\n",
      "          -0.0402, -0.0838,  0.0965,  0.0592,  0.0412,  0.1616,  0.0058,\n",
      "           0.0564, -0.2729,  0.1326,  0.0932, -0.0417,  0.2144,  0.1090,\n",
      "           0.1803, -0.1572,  0.0505,  0.0133,  0.0453,  0.3039,  0.0514,\n",
      "           0.0666, -0.0094,  0.0282, -0.1417, -0.0586,  0.0065,  0.0311,\n",
      "           0.0324,  0.1317,  0.0335,  0.0312,  0.0910, -0.1729,  0.1731,\n",
      "          -0.0232,  0.2163,  0.0919,  0.0315,  0.2251,  0.0916, -0.0167,\n",
      "           0.1853, -0.2478, -0.1667,  0.0044,  0.0083, -0.1438,  0.0542,\n",
      "           0.0707,  0.0272, -0.0901, -0.0688, -0.1049, -0.1291, -0.1417,\n",
      "          -0.0130, -0.1379, -0.3967, -0.1714, -0.0135,  0.1496, -0.1593,\n",
      "           0.2256,  0.0596, -0.0329, -0.0641,  0.0285, -0.1262,  0.1494,\n",
      "          -0.0891, -0.0858, -0.0184, -0.0658,  0.0802, -0.0401,  0.0720,\n",
      "          -0.0070,  0.0276,  0.1035, -0.0321,  0.2498,  0.0414, -0.1112,\n",
      "           0.1681,  0.1555, -0.0051,  0.0553,  0.0949, -0.0066, -0.1220,\n",
      "          -0.0331, -0.0363,  0.1893,  0.1201, -0.0459, -0.3801, -0.0299,\n",
      "           0.0846, -0.0465,  0.0104, -0.1301, -0.1228, -0.1203, -0.0155,\n",
      "          -0.1040, -0.0170, -0.1579, -0.1857, -0.0303,  0.1308, -0.0212,\n",
      "           0.0151, -0.0202, -0.1805, -0.0174,  0.1691,  0.0537,  0.1114,\n",
      "           0.0221,  0.0133, -0.1029,  0.0566,  0.0171,  0.0881,  0.1861,\n",
      "           0.2538,  0.2303, -0.0114,  0.0124, -0.0528, -0.2063,  0.1186,\n",
      "           0.1617,  0.0713,  0.2129]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.2269, -0.0501, -0.0188,  0.1834, -0.0586,  0.1785,  0.1770,\n",
      "           0.0483, -0.1846,  0.1421,  0.1248, -0.0668, -0.0928,  0.0328,\n",
      "          -0.0483, -0.0441,  0.2240,  0.0155,  0.1173,  0.2233, -0.0845,\n",
      "           0.0221, -0.2208,  0.1552,  0.0674, -0.0930,  0.0958,  0.1622,\n",
      "           0.1359, -0.2337,  0.0436,  0.1993,  0.0695,  0.0751,  0.1744,\n",
      "           0.0304,  0.1155,  0.1182, -0.0815, -0.0461,  0.0315, -0.0862,\n",
      "          -0.0049,  0.0723,  0.0707,  0.0740,  0.0582, -0.1527,  0.1899,\n",
      "          -0.1319,  0.2082,  0.0528, -0.0058,  0.2187,  0.0853, -0.0438,\n",
      "           0.1336, -0.1405, -0.0750, -0.0256,  0.0576, -0.0515, -0.0369,\n",
      "           0.0272, -0.0373, -0.2355, -0.0146, -0.1658, -0.1171, -0.1556,\n",
      "          -0.0294, -0.1258, -0.3172, -0.1022, -0.0005,  0.0044, -0.1221,\n",
      "           0.0485, -0.0643,  0.0092, -0.0569,  0.1307, -0.1725,  0.0528,\n",
      "          -0.1302, -0.1238,  0.0108,  0.0947,  0.1256,  0.0192, -0.0008,\n",
      "          -0.0027,  0.1135,  0.1810,  0.0203,  0.1283, -0.0804, -0.1064,\n",
      "           0.0479,  0.2643, -0.0946,  0.0937,  0.1113, -0.0235, -0.1194,\n",
      "          -0.1420, -0.1140,  0.2900,  0.0870,  0.0102, -0.2855, -0.0245,\n",
      "           0.1608, -0.0860,  0.0406, -0.1728, -0.1086, -0.0483, -0.0548,\n",
      "          -0.0905,  0.0907, -0.1108, -0.1598, -0.0996,  0.0699, -0.0216,\n",
      "          -0.0219,  0.0631, -0.1918,  0.0327,  0.1387,  0.0301,  0.0718,\n",
      "           0.0197,  0.0032, -0.0921,  0.1046, -0.0012, -0.1027,  0.1344,\n",
      "           0.2669,  0.1742, -0.0197,  0.0589, -0.0579, -0.2195,  0.1589,\n",
      "           0.1210, -0.0401, -0.0703]]], grad_fn=<CatBackward>)\n",
      "tensor([[[ 0.0523,  0.0025, -0.1012,  0.0624,  0.0126,  0.1182,  0.1388,\n",
      "          -0.0535, -0.2178,  0.3300,  0.3154, -0.0335,  0.1466, -0.0601,\n",
      "          -0.0147,  0.0867,  0.2948, -0.2701, -0.0175,  0.2177, -0.0394,\n",
      "          -0.1071,  0.0199,  0.1429, -0.0471, -0.0532,  0.0706, -0.0520,\n",
      "          -0.1577, -0.1002,  0.0589,  0.1048,  0.0198,  0.0963,  0.0632,\n",
      "           0.1120,  0.0694,  0.0351, -0.0424,  0.0370,  0.0336, -0.1038,\n",
      "          -0.0373,  0.0272,  0.1342,  0.0262, -0.0020,  0.0023,  0.0615,\n",
      "          -0.1720,  0.0210,  0.0864,  0.1356,  0.0852,  0.0833, -0.1051,\n",
      "           0.0004, -0.0345,  0.0724, -0.0961,  0.0386, -0.1774,  0.0469,\n",
      "           0.1738, -0.0635, -0.1441, -0.0637, -0.2716, -0.0648,  0.0377,\n",
      "           0.0613, -0.0206, -0.1421,  0.1313,  0.0132,  0.0875, -0.1351,\n",
      "          -0.0709,  0.0093, -0.1088, -0.0716,  0.2370, -0.1287,  0.0449,\n",
      "          -0.0096, -0.0360,  0.0945,  0.2031, -0.0570,  0.1112, -0.1256,\n",
      "           0.0434,  0.1832,  0.0586,  0.0459,  0.1609, -0.0350, -0.0768,\n",
      "          -0.0094,  0.0246, -0.2592, -0.1248,  0.0556, -0.0849, -0.1181,\n",
      "           0.1506, -0.0623,  0.2066,  0.0941,  0.0634, -0.2104, -0.2049,\n",
      "           0.1508, -0.0486,  0.0949, -0.0490, -0.0498, -0.0172, -0.1318,\n",
      "           0.1254,  0.1136,  0.1171, -0.0455, -0.2103,  0.1046, -0.0853,\n",
      "           0.0495, -0.0314,  0.0134, -0.1113,  0.2189,  0.0854,  0.0924,\n",
      "          -0.2135,  0.1162, -0.1197,  0.1395, -0.0720, -0.0734,  0.0560,\n",
      "           0.1301,  0.1468, -0.1039, -0.1154,  0.0510,  0.0483,  0.1545,\n",
      "           0.2311,  0.0218,  0.1508]]], grad_fn=<CatBackward>)\n",
      "[tensor([1]), tensor([181]), tensor([1195]), tensor([304]), tensor([17]), tensor([7711]), tensor([127]), tensor([886]), tensor([5]), tensor([163]), tensor([2008]), tensor([316]), tensor([4]), tensor([173]), tensor([17]), tensor([7711]), tensor([2264]), tensor([109]), tensor([4]), tensor([2264]), tensor([1122]), tensor([4]), tensor([2264]), tensor([2022]), tensor([4]), tensor([748]), tensor([9029]), tensor([210]), tensor([6]), tensor([2])]\n",
      "[tensor([1]), tensor([124]), tensor([1211]), tensor([264]), tensor([10]), tensor([236]), tensor([6]), tensor([164]), tensor([5]), tensor([60]), tensor([46]), tensor([35]), tensor([94]), tensor([916]), tensor([36]), tensor([2783]), tensor([18]), tensor([4]), tensor([407]), tensor([6]), tensor([2953]), tensor([293]), tensor([7]), tensor([562]), tensor([6]), tensor([1197]), tensor([5]), tensor([83]), tensor([49]), tensor([572]), tensor([316]), tensor([9]), tensor([264]), tensor([10]), tensor([1427]), tensor([5]), tensor([590]), tensor([838]), tensor([6]), tensor([10957]), tensor([6]), tensor([9]), tensor([4980]), tensor([1448]), tensor([8669]), tensor([8]), tensor([2])]\n"
     ]
    }
   ],
   "source": [
    "for idx, data in enumerate(train_dataloader, 0):\n",
    "    src = data[0]\n",
    "    outs= []\n",
    "    h, c = enc.initHiddenCell()\n",
    "    for i in range(len(src)):\n",
    "        out,h,c = enc(src[i], h, c)\n",
    "#         print(out)\n",
    "        outs.append(out)\n",
    "    \n",
    "    for j in range(len(tgt)):\n",
    "        \n",
    "    \n",
    "    \n",
    "    print(src)\n",
    "    print(tgt)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_en_embedding(word_dict, embedding_path, embedding_dim=300):\n",
    "    \"\"\"\n",
    "\n",
    "    :param word_dict: vocabulary words' list\n",
    "    :param embedding_path: pre-trained embedding path\n",
    "    :param embedding_dim: embedding dimensions\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # find existing word embeddings\n",
    "    word_vec = {}\n",
    "    with open(embedding_path) as f:\n",
    "        for line in f:\n",
    "            word, vec = line.split(' ', 1)\n",
    "            if word in word_dict:\n",
    "                word_vec[word] = np.array(list(map(float, vec.split())))\n",
    "    \n",
    "    \n",
    "    print('Found {0}/{1} words with embedding vectors'.format(\n",
    "        len(word_vec), len(word_dict)))\n",
    "    missing_word_num = len(word_dict) - len(word_vec)\n",
    "    missing_ratio = round(float(missing_word_num) / len(word_dict), 4) * 100\n",
    "    print('Missing Ratio: {}%'.format(missing_ratio))\n",
    "\n",
    "    # handling unknown embeddings\n",
    "    for word in word_dict:\n",
    "        if word not in word_vec:\n",
    "            # If word not in word_vec, create a random embedding for it\n",
    "            new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "            word_vec[word] = new_embedding\n",
    "    print(\"Filled missing words' embeddings.\")\n",
    "    print(\"Embedding Matrix Size: \", len(word_vec))\n",
    "\n",
    "    return word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cn_embeding(word_dict, full_embedding, embedding_dim=300):\n",
    "    \n",
    "    word_vec = {}\n",
    "    count = 0\n",
    "\n",
    "    for word in word_dict:\n",
    "        if word in full_embedding.vocab:\n",
    "            word_vec[word] = full_embedding[word]\n",
    "            count+=1\n",
    "        else: \n",
    "            new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "            word_vec[word] = new_embedding\n",
    "\n",
    "    print('Found {0}/{1} words with full embedding vectors'.format(\n",
    "        count, len(word_dict)))\n",
    "\n",
    "    missing_word_num = len(word_dict) - count\n",
    "    missing_ratio = round(float(missing_word_num) / len(word_dict), 4) * 100\n",
    "    print('Missing Ratio: {}%'.format(missing_ratio))\n",
    "    print(\"Filled missing words' embeddings.\")\n",
    "    print(\"Embedding Matrix Size: \", len(word_vec))\n",
    "    \n",
    "    return word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(config):\n",
    "    \n",
    "    src_lang = config['src_lang']\n",
    "    \n",
    "    \"\"\"\n",
    "    English Embedding\n",
    "    \"\"\"\n",
    "    cur_en_embed_path = config['embedding']['cur_en_embedding_path']\n",
    "    full_en_embed_path = config['embedding']['en_embed_path']\n",
    "\n",
    "    if os.path.exists(cur_en_embed_path) and not config['make_dict']:\n",
    "        en_embed = load_embed(cur_en_embed_path)\n",
    "        print('Loaded existing english embedding, containing {} words.'.format(len(en_embed)))\n",
    "    else:\n",
    "        print('Making embedding...')\n",
    "        en_embed = get_embedding(train_ds.tgt_vocab._id2word, full_en_embed_path)\n",
    "        save_embed(en_embed,cur_en_embed_path)\n",
    "        print('Saved generated embedding.')\n",
    "        \n",
    "    \"\"\"\n",
    "    Chinese Embedding\n",
    "    \"\"\"\n",
    "    cur_cn_embed_path = config['embedding']['cur_cn_embedding_path']\n",
    "    full_cn_embed_path = config['embedding']['cn_embed_path']\n",
    "\n",
    "    if os.path.exists(cur_cn_embed_path) and not config['make_dict']:\n",
    "        cn_embed = load_embed(cur_cn_embed_path)\n",
    "        print('Loaded existing chinese embedding, containing {} words.'.format(len(cn_embed)))\n",
    "    else:\n",
    "        print('loading full w2v embeddings...')\n",
    "        word_vectors = KeyedVectors.load_word2vec_format('data/sgns.merge.bigram.bz2') \n",
    "        print('start extracting...')\n",
    "        src_embed = get_cn_embeding(train_ds.src_vocab._id2word, word_vectors)\n",
    "        save_embed(src_embed, 'data/cn_embed.pkl')\n",
    "    \n",
    "    \n",
    "    if src_lang == 'chinese':\n",
    "        src_embed = cn_embed\n",
    "        tgt_embed = en_embed\n",
    "    else:\n",
    "        src_embed = en_embed\n",
    "        tgt_embed = cn_embed\n",
    "\n",
    "    src_vocab_size = len(src_embed)\n",
    "    tgt_vocab_size = len(tgt_embed)\n",
    "\n",
    "    # initialize nn embedding\n",
    "    src_embedding = nn.Embedding(src_vocab_size, config['model']['embed_size'])\n",
    "    tgt_embedding = nn.Embedding(tgt_vocab_size, config['model']['embed_size'])\n",
    "\n",
    "    embed_list = []\n",
    "    for word in train_ds.src_vocab._id2word:\n",
    "        embed_list.append(src_embed[word])\n",
    "    weight_matrix = np.array(embed_list)\n",
    "    # pass weights to nn embedding\n",
    "    src_embedding.weight = nn.Parameter(torch.from_numpy(weight_matrix).type(torch.FloatTensor), requires_grad = False)\n",
    "\n",
    "    embed_list = []\n",
    "    for word in train_ds.tgt_vocab._id2word:\n",
    "        embed_list.append(tgt_embed[word])\n",
    "    weight_matrix = np.array(embed_list)\n",
    "    # pass weights to nn embedding\n",
    "    tgt_embedding.weight = nn.Parameter(torch.from_numpy(weight_matrix).type(torch.FloatTensor), requires_grad = False)\n",
    "    \n",
    "    return src_embedding, src_vocab_size, tgt_embedding, tgt_vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing english embedding, containing 35029 words.\n",
      "Loaded existing chinese embedding, containing 53717 words.\n"
     ]
    }
   ],
   "source": [
    "# embedding\n",
    "config['src_embedding_matrix'], config['src_vocab_size'], config['tgt_embedding_matrix'], config['tgt_vocab_size'] = get_embedding(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_embed = config['src_embedding_matrix']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing embedding.\n"
     ]
    }
   ],
   "source": [
    "cur_en_embed_path = config['embedding']['cur_en_embedding_path']\n",
    "full_en_embed_path = config['embedding']['en_embed_path']\n",
    "\n",
    "if os.path.exists(cur_en_embed_path) and not config['make_dict']:\n",
    "    en_embed = load_embed(cur_en_embed_path)\n",
    "    print('Loaded existing embedding.')\n",
    "else:\n",
    "    print('Making embedding...')\n",
    "    en_embed = get_embedding(train_ds.tgt_vocab._id2word, full_en_embed_path)\n",
    "    save_embed(en_embed,cur_en_embed_path)\n",
    "    print('Saved generated embedding.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chinese Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing chinese embedding, containing 53717 words.\n"
     ]
    }
   ],
   "source": [
    "cur_cn_embed_path = config['embedding']['cur_cn_embedding_path']\n",
    "full_cn_embed_path = config['embedding']['cn_embed_path']\n",
    "\n",
    "\"\"\"\"\"\"\n",
    "\n",
    "if os.path.exists(cur_cn_embed_path) and not config['make_dict']:\n",
    "    cn_embed = load_embed(cur_cn_embed_path)\n",
    "    print('Loaded existing chinese embedding, containing {} words.'.format(len(cn_embed)))\n",
    "else:\n",
    "    print('loading full w2v embeddings...')\n",
    "    word_vectors = KeyedVectors.load_word2vec_format('data/sgns.merge.bigram.bz2') \n",
    "    print('start extracting...')\n",
    "    src_embed = get_cn_embeding(train_ds.src_vocab._id2word, word_vectors)\n",
    "    save_embed(src_embed, 'data/cn_embed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "if src_lang == 'chinese':\n",
    "    src_embed = cn_embed\n",
    "    tgt_embed = en_embed\n",
    "else:\n",
    "    src_embed = en_embed\n",
    "    tgt_embed = cn_embed\n",
    "    \n",
    "src_vocab_size = len(src_embed)\n",
    "tgt_vocab_size = len(tgt_embed)\n",
    "\n",
    "# initialize nn embedding\n",
    "src_embedding = nn.Embedding(src_vocab_size, config['model']['embed_size'])\n",
    "tgt_embedding = nn.Embedding(tgt_vocab_size, config['model']['embed_size'])\n",
    "\n",
    "embed_list = []\n",
    "for word in train_ds.src_vocab._id2word:\n",
    "    embed_list.append(src_embed[word])\n",
    "weight_matrix = np.array(embed_list)\n",
    "# pass weights to nn embedding\n",
    "src_embedding.weight = nn.Parameter(torch.from_numpy(weight_matrix).type(torch.FloatTensor), requires_grad = False)\n",
    "\n",
    "embed_list = []\n",
    "for word in train_ds.tgt_vocab._id2word:\n",
    "    embed_list.append(tgt_embed[word])\n",
    "weight_matrix = np.array(embed_list)\n",
    "# pass weights to nn embedding\n",
    "tgt_embedding.weight = nn.Parameter(torch.from_numpy(weight_matrix).type(torch.FloatTensor), requires_grad = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liushijing/anaconda3/envs/python36/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/Users/liushijing/anaconda3/envs/python36/lib/python3.6/site-packages/ipykernel/__main__.py:75: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Epoch 1 Training...\n",
      "tensor(10.4760, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4622, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4784, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4679, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4711, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4740, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4682, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4790, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4559, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4582, grad_fn=<NllLossBackward>)\n",
      "10/80044 loss: 10.469099998474121 \n",
      "tensor(10.4569, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4493, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4611, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4542, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4493, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4502, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4435, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4566, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4684, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4478, grad_fn=<NllLossBackward>)\n",
      "20/80044 loss: 10.461400032043457 \n",
      "tensor(10.4723, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4524, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4671, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4479, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4503, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4388, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4312, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4495, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4433, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4598, grad_fn=<NllLossBackward>)\n",
      "30/80044 loss: 10.458000183105469 \n",
      "tensor(10.4590, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4558, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4628, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4311, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4333, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4446, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4365, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4322, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4389, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4438, grad_fn=<NllLossBackward>)\n",
      "40/80044 loss: 10.454500198364258 \n",
      "tensor(10.4232, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4527, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4305, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4402, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4210, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4494, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4325, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4388, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4349, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4252, grad_fn=<NllLossBackward>)\n",
      "50/80044 loss: 10.450499534606934 \n",
      "tensor(10.4271, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4478, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4217, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4232, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4222, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4234, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4094, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4217, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4297, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4335, grad_fn=<NllLossBackward>)\n",
      "60/80044 loss: 10.446399688720703 \n",
      "tensor(10.4119, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4267, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4152, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4019, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4142, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4172, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4071, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4190, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4142, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4053, grad_fn=<NllLossBackward>)\n",
      "70/80044 loss: 10.441699981689453 \n",
      "tensor(10.4052, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4203, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4070, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4018, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4050, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3937, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4216, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4044, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3669, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3840, grad_fn=<NllLossBackward>)\n",
      "80/80044 loss: 10.436599731445312 \n",
      "tensor(10.4247, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4191, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4208, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3724, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3670, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3846, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3713, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3856, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3983, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3819, grad_fn=<NllLossBackward>)\n",
      "90/80044 loss: 10.431699752807617 \n",
      "tensor(10.4015, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4173, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3829, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3993, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3650, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3917, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3794, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4039, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3959, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3860, grad_fn=<NllLossBackward>)\n",
      "100/80044 loss: 10.427800178527832 \n",
      "tensor(10.3799, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3719, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3831, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4032, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3920, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3643, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3591, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3639, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3924, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3862, grad_fn=<NllLossBackward>)\n",
      "110/80044 loss: 10.423399925231934 \n",
      "tensor(10.3982, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3411, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3542, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3610, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3450, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3702, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3872, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3251, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3768, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3576, grad_fn=<NllLossBackward>)\n",
      "120/80044 loss: 10.418299674987793 \n",
      "tensor(10.3875, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3737, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3669, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3862, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3351, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3858, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3583, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3515, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3462, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3580, grad_fn=<NllLossBackward>)\n",
      "130/80044 loss: 10.414199829101562 \n",
      "tensor(10.3236, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3346, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3665, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3050, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3440, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3469, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3319, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3416, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3414, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3312, grad_fn=<NllLossBackward>)\n",
      "140/80044 loss: 10.408599853515625 \n",
      "tensor(10.3799, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3630, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3231, grad_fn=<NllLossBackward>)\n",
      "tensor(10.2904, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3477, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3571, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3058, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3553, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3080, grad_fn=<NllLossBackward>)\n",
      "tensor(10.2902, grad_fn=<NllLossBackward>)\n",
      "150/80044 loss: 10.403499603271484 \n",
      "tensor(10.3588, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3175, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3151, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3470, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3240, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3243, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3091, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3470, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3478, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3334, grad_fn=<NllLossBackward>)\n",
      "160/80044 loss: 10.399100303649902 \n",
      "tensor(10.2953, grad_fn=<NllLossBackward>)\n",
      "tensor(10.2963, grad_fn=<NllLossBackward>)\n",
      "tensor(10.2781, grad_fn=<NllLossBackward>)\n",
      "tensor(10.2924, grad_fn=<NllLossBackward>)\n",
      "tensor(10.2527, grad_fn=<NllLossBackward>)\n",
      "tensor(10.2838, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3325, grad_fn=<NllLossBackward>)\n",
      "tensor(10.2936, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3003, grad_fn=<NllLossBackward>)\n",
      "tensor(10.2988, grad_fn=<NllLossBackward>)\n",
      "170/80044 loss: 10.392800331115723 \n",
      "tensor(10.3005, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3714, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-a2fd6515dedf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m# Teacher forcing: Feed the target as the next input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mdec_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-750667a64e52>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, cell, encoder_outputs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# model\n",
    "enc = LSTMEncoder(config)\n",
    "dec = AttnLSTMDecoder(config)\n",
    "\n",
    "# data loader\n",
    "train_dataloader = DataLoader(dataset=train_ds, shuffle=True, batch_size=config['model']['batch_size'])\n",
    "teacher_forcing_ratio = 1.0\n",
    "\n",
    "# loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# optimizer\n",
    "enc_optimizer = optim.SGD(enc.parameters(), lr=config['training']['learning_rate'])\n",
    "dec_optimizer = optim.SGD(dec.parameters(), lr=config['training']['learning_rate'])\n",
    "\n",
    "SOS_TOKEN = train_ds.tgt_vocab._word2id[train_ds.tgt_vocab.sos_token]\n",
    "EOS_TOKEN = train_ds.tgt_vocab._word2id[train_ds.tgt_vocab.eos_token]\n",
    "\n",
    "epoch = 1\n",
    "\n",
    "best_record = 100.0\n",
    "\n",
    "while epoch < config['training']['num_epochs']:\n",
    "\n",
    "    # Train\n",
    "    print('Start Epoch {} Training...'.format(epoch))\n",
    "    \n",
    "    train_loss = []\n",
    "    \n",
    "    for idx, data in enumerate(train_dataloader, 0):\n",
    "\n",
    "        src = data[0]\n",
    "        tgt = data[1]\n",
    "\n",
    "        loss = 0    \n",
    "\n",
    "        # Encoder \n",
    "        enc_outputs = torch.zeros(config['max_length'], enc.hidden_size, device=device)\n",
    "        enc_h, enc_c = enc.initHiddenCell()\n",
    "        for i in range(len(src)):\n",
    "            enc_out, enc_h, enc_c = enc(src[i], enc_h, enc_c)\n",
    "            enc_outputs[i] = enc_out[0, 0]\n",
    "\n",
    "\n",
    "        dec_in = torch.tensor(SOS_TOKEN, device=device).repeat(config['model']['batch_size'])\n",
    "        dec_h = enc_h\n",
    "        dec_c = enc_c\n",
    "\n",
    "        # Decoder\n",
    "\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            # Teacher forcing: Feed the target as the next input\n",
    "            for j in range(len(tgt)-1):\n",
    "                dec_out, dec_h, dec_att = dec(dec_in, dec_h, dec_c, enc_outputs)\n",
    "                print(criterion(dec_out, tgt[j+1]))\n",
    "                loss += criterion(dec_out, tgt[j+1])\n",
    "                dec_in = tgt[j+1]  # Teacher forcing\n",
    "                break\n",
    "        else:\n",
    "            # Without teacher forcing: use its own predictions as the next input\n",
    "            for j in range(len(tgt)-1):\n",
    "                dec_out, dec_h, dec_att = dec(dec_in, dec_h, dec_c, enc_outputs)\n",
    "\n",
    "                topv, topi = dec_out.topk(1)\n",
    "\n",
    "                dec_in = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "                loss += criterion(dec_out, tgt[j+1])\n",
    "    #             if dec_in == dec.embedding(torch.tensor(EOS_TOKEN, device=device)):\n",
    "    #                 break\n",
    "\n",
    "        train_loss.append(loss.data[0])\n",
    "\n",
    "        enc_optimizer.zero_grad()\n",
    "        dec_optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        enc_optimizer.step()\n",
    "        dec_optimizer.step()\n",
    "\n",
    "        if(len(train_loss)) % 10 == 0:\n",
    "            print(\"{}/{} loss: {} \".format(idx+1, len(train_ds.src), round(np.mean(train_loss),4)))\n",
    "\n",
    "        \n",
    "#     # Valid\n",
    "#     print('Epoch {} Validating...'.format(epoch))\n",
    "\n",
    "#     # loss\n",
    "#     valid_loss = []\n",
    "    \n",
    "#     # dataloader\n",
    "#     valid_dataloader = DataLoader(dataset=valid_ds, shuffle=True, num_workers=2, batch_size=config['model']['batch_size'])\n",
    "\n",
    "#     for idx, data in enumerate(valid_dataloader, 0):\n",
    "#         src = data[0]\n",
    "#         tgt = data[1]\n",
    "\n",
    "#         # Encoder \n",
    "#         enc_outputs = torch.zeros(config['max_length'], enc.hidden_size, device=device)\n",
    "#         enc_h, enc_c = enc.initHiddenCell()\n",
    "#         for i in range(len(src)):\n",
    "#             enc_out, enc_h, enc_c = enc(src[i], enc_h, enc_c)\n",
    "#             enc_outputs[i] = enc_out[0, 0]\n",
    "\n",
    "\n",
    "#         dec_in = torch.tensor(SOS_TOKEN, device=device).repeat(64)\n",
    "#         dec_h = enc_h\n",
    "#         dec_c = enc_c\n",
    "\n",
    "#         for j in range(len(tgt)-1):\n",
    "#             dec_out, dec_h, dec_att = dec(dec_in, dec_h, dec_c, enc_outputs)\n",
    "#             loss += criterion(dec_out, tgt[j+1])\n",
    "#             dec_in = tgt[j+1]  # Teacher forcing\n",
    "            \n",
    "#         valid_loss.append(loss.data[0])\n",
    "    \n",
    "#     print('Epoch {} Validation Loss: {}'.format(epoch, np.mean(valid_loss)))\n",
    "    \n",
    "#     epoch += 1\n",
    "    \n",
    "#     # Keep track of best record\n",
    "#     if np.mean(valid_loss) < best_record:\n",
    "#         best_record = np.mean(valid_loss)\n",
    "#         # save the best model\n",
    "#         state_dict = {\n",
    "#             'epoch': epoch,\n",
    "#             'siamese': siamese.state_dict(),\n",
    "#             'optimizer': optimizer.state_dict(),\n",
    "#         }\n",
    "#         torch.save(state_dict, ckpt_path)\n",
    "#         print('Model saved!\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnLSTMDecoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(AttnLSTMDecoder, self).__init__()\n",
    "        self.hidden_size = config['model']['decoder']['hidden_size']\n",
    "        self.output_size = config['tgt_vocab_size']\n",
    "        self.num_layers = config['model']['decoder']['num_layers']\n",
    "        self.dropout_p = config['model']['decoder']['dropout']\n",
    "        self.bidir = config['model']['decoder']['bidirectional']\n",
    "        self.embed_size = config['model']['embed_size']\n",
    "        self.embedding = config['src_embedding_matrix']\n",
    "        self.batch_size = config['model']['batch_size']\n",
    "        \n",
    "        self.max_length = config['max_length']\n",
    "        \n",
    "        \n",
    "        self.attn = nn.Linear(self.hidden_size + self.embed_size, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size + self.embed_size, self.embed_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.embed_size, hidden_size=self.hidden_size, dropout=self.dropout_p,\n",
    "                            num_layers=self.num_layers, bidirectional=self.bidir)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, self.batch_size, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        output, (hidden,cell) = self.lstm(output, (hidden, cell))\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.embed_size = config['model']['embed_size']\n",
    "        self.batch_size = config['model']['batch_size']\n",
    "#         self.batch_size = config['model']['batch_size']\n",
    "\n",
    "        self.hidden_size = config['model']['encoder']['hidden_size']\n",
    "        self.num_layers = config['model']['encoder']['num_layers']\n",
    "        self.bidir = config['model']['encoder']['bidirectional']\n",
    "        if self.bidir:\n",
    "            self.direction = 2\n",
    "        else: self.direction = 1\n",
    "        self.dropout = config['model']['encoder']['dropout']\n",
    "\n",
    "        self.embedding = config['src_embedding_matrix']\n",
    "        self.lstm = nn.LSTM(input_size=self.embed_size, hidden_size=self.hidden_size, dropout=self.dropout,\n",
    "                            num_layers=self.num_layers, bidirectional=self.bidir)\n",
    "\n",
    "    def initHiddenCell(self):\n",
    "        rand_hidden = Variable(torch.randn(self.direction * self.num_layers, self.batch_size, self.hidden_size))\n",
    "        rand_cell = Variable(torch.randn(self.direction * self.num_layers, self.batch_size, self.hidden_size))\n",
    "        if torch.cuda.is_available():\n",
    "            rand_hidden = rand_hidden.cuda()\n",
    "            rand_cell = rand_cell.cuda()\n",
    "        return rand_hidden, rand_cell\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = self.embedding(input).view(1,self.batch_size, -1)\n",
    "        output, (hidden, cell) = self.lstm(input, (hidden, cell))\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = config['src_vocab_size']\n",
    "        self.batch_size = config['model']['batch_size']\n",
    "        self.hidden_size = config['model']['encoder']['hidden_size']\n",
    "        self.embed_size = config['model']['embed_size']\n",
    "        self.n_layers = config['model']['encoder']['num_layers']\n",
    "        self.dropout = config['model']['encoder']['dropout']\n",
    "        self.embedding = config['src_embedding_matrix']\n",
    "        if config['model']['encoder']['bidirectional']:\n",
    "            self.direction = 2\n",
    "        else: self.direction = 1\n",
    "        self.gru = nn.GRU(self.embed_size, self.hidden_size, self.n_layers, dropout=self.dropout, bidirectional=config['model']['encoder']['bidirectional'])\n",
    "\n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        '''\n",
    "        :param input_seqs: \n",
    "            Variable of shape (num_step(T),batch_size(B)), sorted decreasingly by lengths(for packing)\n",
    "        :param input:\n",
    "            list of sequence length\n",
    "        :param hidden:\n",
    "            initial state of GRU\n",
    "        :returns:\n",
    "            GRU outputs in shape (T,B,hidden_size(H))\n",
    "            last hidden stat of RNN(i.e. last output for GRU)\n",
    "        '''\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs)  # unpack (back to padded)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]  # Sum bidirectional outputs\n",
    "        return outputs, hidden\n",
    "    \n",
    "#     def initHiddenCell(self):\n",
    "#         rand_hidden = Variable(torch.randn(self.direction * self.n_layers, self.batch_size, self.hidden_size))\n",
    "#         rand_cell = Variable(torch.randn(self.direction * self.n_layers, self.batch_size, self.hidden_size))\n",
    "#         if torch.cuda.is_available():\n",
    "#             rand_hidden = rand_hidden.cuda()\n",
    "#             rand_cell = rand_cell.cuda()\n",
    "#         return rand_hidden, rand_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = config['model']['decoder']['hidden_size']\n",
    "        self.output_size =  config['tgt_vocab_size']\n",
    "        self.dropout_p = config['model']['decoder']['dropout']\n",
    "        self.max_length = config['max_length']\n",
    "\n",
    "        self.embedding = config['tgt_embedding_matrix']\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicEncoder(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size, n_layers=1, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Embedding(input_size, embed_size)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, n_layers, bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seqs, input_lens, hidden=None):\n",
    "        \"\"\"\n",
    "        forward procedure. **No need for inputs to be sorted**\n",
    "        :param input_seqs: Variable of [T,B]\n",
    "        :param hidden:\n",
    "        :param input_lens: *numpy array* of len for each input sequence\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        batch_size = input_seqs.size(1)\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        embedded = embedded.transpose(0, 1)  # [B,T,E]\n",
    "        sort_idx = np.argsort(-input_lens)\n",
    "        unsort_idx = cuda_(torch.LongTensor(np.argsort(sort_idx)))\n",
    "        input_lens = input_lens[sort_idx]\n",
    "        sort_idx = cuda_(torch.LongTensor(sort_idx))\n",
    "        embedded = embedded[sort_idx].transpose(0, 1)  # [T,B,E]\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lens)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
    "        outputs = outputs.transpose(0, 1)[unsort_idx].transpose(0, 1).contiguous()\n",
    "        hidden = hidden.transpose(0, 1)[unsort_idx].transpose(0, 1).contiguous()\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        stdv = 1. / math.sqrt(self.v.size(0))\n",
    "        self.v.data.normal_(mean=0, std=stdv)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        '''\n",
    "        :param hidden: \n",
    "            previous hidden state of the decoder, in shape (layers*directions,B,H)\n",
    "        :param encoder_outputs:\n",
    "            encoder outputs from Encoder, in shape (T,B,H)\n",
    "        :return\n",
    "            attention energies in shape (B,T)\n",
    "        '''\n",
    "        max_len = encoder_outputs.size(0)\n",
    "        this_batch_size = encoder_outputs.size(1)\n",
    "        H = hidden.repeat(max_len,1,1).transpose(0,1)\n",
    "        encoder_outputs = encoder_outputs.transpose(0,1) # [B*T*H]\n",
    "        attn_energies = self.score(H,encoder_outputs) # compute attention score\n",
    "        return F.softmax(attn_energies).unsqueeze(1) # normalize with softmax\n",
    "\n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        energy = F.tanh(self.attn(torch.cat([hidden, encoder_outputs], 2))) # [B*T*2H]->[B*T*H]\n",
    "        energy = energy.transpose(2,1) # [B*H*T]\n",
    "        v = self.v.repeat(encoder_outputs.data.shape[0],1).unsqueeze(1) #[B*1*H]\n",
    "        energy = torch.bmm(v,energy) # [B*1*T]\n",
    "        return energy.squeeze(1) #[B*T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embed_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(BahdanauAttnDecoderRNN, self).__init__()\n",
    "        # Define parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = Attn('concat', hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size + embed_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        #self.attn_combine = nn.Linear(hidden_size + embed_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        '''\n",
    "        :param word_input:\n",
    "            word input for current time step, in shape (B)\n",
    "        :param last_hidden:\n",
    "            last hidden stat of the decoder, in shape (layers*direction*B*H)\n",
    "        :param encoder_outputs:\n",
    "            encoder outputs in shape (T*B*H)\n",
    "        :return\n",
    "            decoder output\n",
    "        Note: we run this one step at a time i.e. you should use a outer loop \n",
    "            to process the whole sequence\n",
    "        Tip(update):\n",
    "        EncoderRNN may be bidirectional or have multiple layers, so the shape of hidden states can be \n",
    "        different from that of DecoderRNN\n",
    "        You may have to manually guarantee that they have the same dimension outside this function,\n",
    "        e.g, select the encoder hidden state of the foward/backward pass.\n",
    "        '''\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, word_input.size(0), -1) # (1,B,V)\n",
    "        word_embedded = self.dropout(word_embedded)\n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))  # (B,1,V)\n",
    "        context = context.transpose(0, 1)  # (1,B,V)\n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, context), 2)\n",
    "        #rnn_input = self.attn_combine(rnn_input) # use it in case your size of rnn_input is different\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        output = output.squeeze(0)  # (1,B,V)->(B,V)\n",
    "        # context = context.squeeze(0)\n",
    "        # update: \"context\" input before final layer can be problematic.\n",
    "        # output = F.log_softmax(self.out(torch.cat((output, context), 1)))\n",
    "        output = F.log_softmax(self.out(output))\n",
    "        # Return final output, hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\n",
    "src = tensorFromSentence(train_ds.src_vocab, sentence)\n",
    "\n",
    "# # Encoder\n",
    "# enc_outputs = torch.zeros(config['max_length'], enc.hidden_size, device=device)\n",
    "# enc_h, enc_c = enc.initHiddenCell()\n",
    "\n",
    "# for i in range(len(src)):\n",
    "#     enc_out, enc_h, enc_c = enc(src[i], enc_h, enc_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(vocab, sentence):\n",
    "    return [vocab.word2id(word) for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_TOKEN)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(enc, dec, src, max_length=config['max_length']):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        input_tensor = tensorFromSentence(train_ds.src_vocab, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        \n",
    "\n",
    "        # Encoder\n",
    "        enc_outputs = torch.zeros(config['max_length'], enc.hidden_size, device=device)\n",
    "        enc_h, enc_c = enc.initHiddenCell()\n",
    "        for i in range(len(src)):\n",
    "            enc_out, enc_h, enc_c = enc(src[i], enc_h, enc_c)\n",
    "            if i >= config['max_length']:\n",
    "                break\n",
    "            enc_outputs[i] = enc_out[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_TOKEN]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_TOKEN:\n",
    "                decoded_words.append('<eos>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
